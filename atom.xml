<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jiawen and her funny friends</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2022-05-03T11:48:22.936Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Jiawen Zhang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Summary of Self-Supervised Learning</title>
    <link href="http://yoursite.com/2022/05/03/Summary-of-Self-Supervised-Learning/"/>
    <id>http://yoursite.com/2022/05/03/Summary-of-Self-Supervised-Learning/</id>
    <published>2022-05-03T11:31:22.000Z</published>
    <updated>2022-05-03T11:48:22.936Z</updated>
    
    <content type="html"><![CDATA[<p>近期自监督学习论文总结。</p><a id="more"></a><h1 id="MoCo-Momentum-Contrast-for-Unsupervised-Visual-Representation-Learning-CVPR-2020"><a href="#MoCo-Momentum-Contrast-for-Unsupervised-Visual-Representation-Learning-CVPR-2020" class="headerlink" title="MoCo (Momentum Contrast for Unsupervised Visual Representation Learning, CVPR 2020)"></a>MoCo (Momentum Contrast for Unsupervised Visual Representation Learning, CVPR 2020)</h1><h2 id="Main-idea"><a href="#Main-idea" class="headerlink" title="Main idea"></a>Main idea</h2><p>采用对比学习的方式学习图片表征，其核心是引入了具有队列的动态字典以及移动平均编码器。</p><ol><li>它将dict size与mini-batch size解耦，将队列的大小作为超参数，而字典中的样本将被渐进替换。</li><li>此外，若直接把encoder q中的参数拷贝到encoder k中，快速变化的encoder将降低表示的一致性。因此，该工作采取了momentum update的方式，仅对encoder k进行少量更新。</li></ol><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p><a href="https://imgtu.com/i/IlFJGd" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/11/06/IlFJGd.png" alt="IlFJGd.png"></a></p><p>InFoNCE: 选取$[k_1,…,k_{K+1}]$, 含一个正样本$k_+$, K个负样本$k_i$ (其他随便信号)。</p><script type="math/tex; mode=display">\mathcal{L}_q = - \rm{log} \frac{\rm{exp}(q \cdot k_{+} / \tau)}{\sum^{K}_{i=0} \exp (q \cdot k_i / \tau)}</script><p>Momentum Update</p><script type="math/tex; mode=display">\theta_k \leftarrow m \theta_k + (1-m) \theta_q</script><h1 id="BYOL-Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning-NIPS-2020"><a href="#BYOL-Bootstrap-Your-Own-Latent-A-New-Approach-to-Self-Supervised-Learning-NIPS-2020" class="headerlink" title="BYOL (Bootstrap Your Own Latent A New Approach to Self-Supervised Learning, NIPS 2020)"></a>BYOL (Bootstrap Your Own Latent A New Approach to Self-Supervised Learning, NIPS 2020)</h1><h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p>现有的图片表示对比学习将同一图片的不同增强视图作为正样本，通过约束同一张图的不同形态之间的特征差异性来实现特征提取（一般通过数据增强实现）。<br>若仅有正样本，网络容易对所有输入都输出一个固定的值，这样特征差异性就是0，完美符合优化目标，但这不是我们想要的，即导致了Collapsing。</p><p>负样本对解决了训练崩塌的问题，但对数量要求较大，因为只有这样才能训练出足够强的特征提取能力，因此往往需要较大的batch size才能有较好的效果。</p><p>BYOL无负样本对，通过增加prediction和stop-gradient避免训练退化。</p><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>作者首先展示了一个实验，一个网络参数随机初始化且固定的target network的top1准确率只有1.4%，而target network输出feature作为另一个叫online network的训练目标，等这个online network训练好之后，online network的top1准确率可以达到18.8%。</p><p>假如将target network替换为效果更好的网络参数（比如此时的online network），然后再迭代一次，也就是再训练一轮online network，去学习新的target network输出的feature，那效果应该是不断上升的，类似左右脚踩楼梯不断上升一样。</p><h2 id="Method-1"><a href="#Method-1" class="headerlink" title="Method"></a>Method</h2><p><a href="https://imgtu.com/i/5XeZOH" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/10/29/5XeZOH.png" alt="5XeZOH.png"></a></p><p>给定一个target network产生表示，用一个online network去预测target表示。若target与online同步更新，表现很差；若保持target不变，acc约18.8%。因此对target采用EMA（Exponential Moving Average）策略。</p><p>给定a set of weights of online network $\theta$, a set of weight of target network $\xi$,  target decay rate $\tau \in [0, 1]$,在训练之后进行以下更新：</p><script type="math/tex; mode=display">\xi \leftarrow \tau \xi + (1- \tau) \theta</script><p>A set of images: $\mathcal{D}$, an image $x~\mathcal{D}$ sampled uniformly.<br>图像增强分布$\mathcal{T}$ and $\mathcal{T}$. \<br>$v \triangleq t(x)$ and $v’ \triangleq t’(x)$: two augmented views from $x$.</p><p>$y_{\theta} \triangleq f_{\theta} (v)$: online network产生的表示 \<br>$z_{\theta} \triangleq g_{\theta} (y)$: projection \<br>$q_{\theta}(z_{\theta})$: prediction of $z’_{\xi}$ \<br>分别对$q_{\theta}(z_{\theta})$和$z’_{\xi}$进行l2 归一化：<br>$\overline{q}_{\theta}(z_{\theta}) \triangleq q_{\theta}(z_{\theta}) / || q_{\theta}(z_{\theta}) ||_2$, $\overline{z}_{\theta} \triangleq z’_{\xi} / ||z’_{\xi}||_2$</p><p>仅有online有predictor，两个branch之间是非对称的。</p><p>计算online的prediction和target的projection的MSE。</p><script type="math/tex; mode=display">\mathcal{L}_{\theta , \xi} \triangleq || \overline{q_{\theta}} - \overline{z_{\xi}}' ||_2^2 = 2-2 \cdot \frac{<q_{\theta}, z'_{\xi}>}{||q_{\theta}||_2 \cdot ||z'_{\xi}||_2}</script><p>分别将$v’$输入online network、$v$输入target network计算$\widetilde{\mathcal{L}}_{\theta , \xi}$，使得loss $\mathcal{L}_{\theta , \xi}$对称。</p><p>在每个训练步进行随机优化，针对$\theta$最小化$\mathcal{L}^{BYOL}_{\theta, \xi}=\mathcal{L}_{\theta , \xi} + \widetilde{\mathcal{L}}_{\theta , \xi}$,而$\xi$则采取stop gradient策略。</p><script type="math/tex; mode=display">\theta \leftarrow \rm{optimizer}(\theta, \nabla_{\theta} \mathcal{L}^{BYOL}_{\theta, \xi}, \eta) \xi \leftarrow \tau \xi + (1-\tau) \theta</script><p>其中$\eta$是个可学习参数。</p><h1 id="ALBEF-Align-before-Fuse-Vision-and-Language-Representation-Learning-with-Momentum-Distillation-NIPS-2021"><a href="#ALBEF-Align-before-Fuse-Vision-and-Language-Representation-Learning-with-Momentum-Distillation-NIPS-2021" class="headerlink" title="ALBEF (Align before Fuse: Vision and Language Representation Learning with Momentum Distillation, NIPS 2021)"></a>ALBEF (Align before Fuse: Vision and Language Representation Learning with Momentum Distillation, NIPS 2021)</h1><h2 id="Main-idea-1"><a href="#Main-idea-1" class="headerlink" title="Main idea"></a>Main idea</h2><p>大多数现有基于transformer作为多模编码器的工作共同建模visual tokens和word tokens，然而token之间是非对齐的，往往难以捕捉它们之间的交互。<br>本文提出，</p><ol><li>采用对比损失在cross-modal attention fusing之前对图像和文本进行对齐。</li><li>为了应对噪声，提出momentum distillation，从momentum model所产生的伪标签中学习。</li></ol><h2 id="Method-2"><a href="#Method-2" class="headerlink" title="Method"></a>Method</h2><p><a href="https://imgtu.com/i/5XeMkt" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/10/29/5XeMkt.png" alt="5XeMkt.png"></a></p><h3 id="Pre-training-Objectives"><a href="#Pre-training-Objectives" class="headerlink" title="Pre-training Objectives"></a>Pre-training Objectives</h3><h4 id="Image-Text-Contrastive-Learning"><a href="#Image-Text-Contrastive-Learning" class="headerlink" title="Image-Text Contrastive Learning"></a>Image-Text Contrastive Learning</h4><p>对比损失旨在在融合之前学习一个更好的单模表示。</p><p>需要学习一个similarity function $s=g_v (\bold{v}_{cls})^{\top} g_w (\bold{w}_{cls})$。受MoCo启发，维护了两个队列来保存由momentum unimodal encoders产生的最近的M个图片-文本表示。由momentum encoders所产生的归一化的特征表示为$g’_v (\bold{v}_{cls}’)$和$g’_w (\bold{w}_{cls}’)$。<br>我们定义$s(I,T)=g_v (\bold{v}_{cls})^{\top}g_w’ (\bold{w}_{cls}’)$, $s(T,I)=g_w (\bold{w}_{cls})^{\top}g_v’ (\bold{v}_{cls}’)$.</p><p>calculate the softmax-normalized image-to-text and text-to-image<br>similarity as:</p><script type="math/tex; mode=display">p^{i2t}_m (I)=\frac{\exp (s(I,T_m)/ \tau)}{\sum_{m=1}^{M} \exp (s(I, T_m)/\tau)}, p^{t2i}_m (T)=\frac{\exp (s(T,I_m)/ \tau)}{\sum_{m=1}^{M} \exp (s(T, I_m)/\tau)}</script><p>$\tau$: learnable temperature parameter</p><p>$\bold{y}^{i2t}(I)$ and $\bold{y}^{t2i}(T)$: ground-truth<br>one-hot similarity</p><p>对比损失被定义为$\bold{p}$和$\bold{y}$的交叉熵。</p><script type="math/tex; mode=display">\mathcal{L}_{itc} = \frac{1}{2} \rm{E}_{(I,T) \backsim D} [\rm{H}(\bold{p}^{i2t}(I), \bold{y}^{i2t}(I)) + \rm{H}(\bold{p}^{t2i}(T), \bold{y}^{t2i}(T))]</script><h4 id="Masked-Language-Modeling"><a href="#Masked-Language-Modeling" class="headerlink" title="Masked Language Modeling"></a>Masked Language Modeling</h4><p>利用图片和上下文文本信息去预测masked words。</p><p>$\hat{T}$: masked text \<br>$\bold{p}^{msk} (I, \hat{T})$: model’s predicted<br>probability for a masked token.</p><p>MLM 最小化交叉熵:</p><script type="math/tex; mode=display">\mathcal{L}_{mlm}=\rm{E}_{(I,\hat{T})\backsim D} \rm{H} (\bold{p}^{msk} (I, \hat{T}, \bold{y}^{msk})</script><p>$\bold{y}^{msk}$: one-hot vocabulary distribution,真实token的概率是1</p><h4 id="Image-Text-Matching"><a href="#Image-Text-Matching" class="headerlink" title="Image-Text Matching"></a>Image-Text Matching</h4><p>预测一组图文对为正（匹配）或负（不匹配）。仅采用[CLS] token的embedding。</p><script type="math/tex; mode=display">\mathcal{L}_{itm} = \rm{E}_{(I,T) \backsim D} \rm{H}(\bold{p}^{itm}(I, T), \bold{y}^{itm})$$$\bold{y}^{itm}$: 2维one-hot ground-truth label向量表示$$\mathcal{L} = \mathcal{L}_{itc} + \mathcal{L}_{mlm} + \mathcal{L}_{itm}</script><h3 id="Momentum-Distillation"><a href="#Momentum-Distillation" class="headerlink" title="Momentum Distillation"></a>Momentum Distillation</h3><p>正样本对往往弱相关，也会包含一些不相关的文本，或实体，而对于ITC学习来说，负文本可能也会包含一些匹配图片的信息。因此采用一个动量模型，它是一个exponential-moving-average<br>versions of the unimodal and multimodal encoders。</p><p>For ITC,首先利用动量单模encoder产生的特征计算相似度：$s’(I,T)=g_v’(\bold{v}_{cls}’)^{\top} g_w’(\bold{w}_{cls}’)$以及$s’(T,I)=g_w’(\bold{w}_{cls}’)^{\top} g_v’(\bold{v}_{cls}’)$</p><p>之后，计算soft pseudo-targets$\bold{q}^{i2t}$和$\bold{q}^{t2i}$,计算损失：</p><script type="math/tex; mode=display">\mathcal{L}^{\rm{mod}}_{\rm{itc}} = (1-\alpha) \mathcal{L}_{itc} + \frac{\alpha}{2} \rm{E}_{(I,T) \backsim D} [\rm{KL}(\bold{p}^{i2t}(I), \bold{q}^{i2t}(I)) + \rm{KL}(\bold{p}^{t2i}(T), \bold{q}^{t2i}(T))]</script><p>For MLM, $\bold{q}^{msk}(I,\hat{T})$表示momentum model’s prediction probability for the<br>masked token, 损失表示为：</p><script type="math/tex; mode=display">\mathcal{L}^{\rm{mod}}_{\rm{mlm}} = (1-\alpha) \mathcal{L}_{mlm} + {\alpha} \rm{E}_{(I,\hat{T}) \backsim D} \rm{KL}(\bold{p}^{msk}(I,\hat{T}),\bold{q}^{msk}(I,\hat{T}))</script><h1 id="Barlow-Twins"><a href="#Barlow-Twins" class="headerlink" title="Barlow Twins"></a>Barlow Twins</h1><p><a href="https://imgtu.com/i/5XebBd" target="_blank" rel="noopener"><img src="https://z3.ax1x.com/2021/10/29/5XebBd.png" alt="5XebBd.png"></a></p><p>将样本经过不同增广送入同一网络中得到两种表示，利用损失函数迫使它们的互相关矩阵接近于恒等矩阵：这意味着同一样本不同的增广版本下提取出的特征表示非常类似，同时特征向量分量间的冗余最小化。</p><p>损失函数如下所示，C为互相关矩阵，其中invariance term使得对角元素接近于1，促使同一样本在不同失真版本下的特征一致性，redundancy reduction term使非对角元素接近0，解耦特征表示的不同向量分量</p><p><img src="https://img-blog.csdnimg.cn/20210320234759199.png" alt="损失函数"></p><p>文中还给出了互相关矩阵C的详细计算公式，如下所示：</p><p><img src="https://img-blog.csdnimg.cn/20210320234825598.png" alt="互相关矩阵"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;近期自监督学习论文总结。&lt;/p&gt;
    
    </summary>
    
    
      <category term="survey" scheme="http://yoursite.com/categories/survey/"/>
    
    
      <category term="Self-supervised Learning" scheme="http://yoursite.com/tags/Self-supervised-Learning/"/>
    
      <category term="Contrasive Learning" scheme="http://yoursite.com/tags/Contrasive-Learning/"/>
    
  </entry>
  
  <entry>
    <title>From CNN to GCNN</title>
    <link href="http://yoursite.com/2022/05/03/From-CNN-to-GCNN/"/>
    <id>http://yoursite.com/2022/05/03/From-CNN-to-GCNN/</id>
    <published>2022-05-03T09:49:46.000Z</published>
    <updated>2022-05-03T10:22:18.203Z</updated>
    
    <content type="html"><![CDATA[<p>CNN无法处理非欧式数据，又希望在拓扑图上有效地提取空间特征来进行机器学习。因此GCNN成为了研究重点。</p><a id="more"></a><h1 id="CNN的性质"><a href="#CNN的性质" class="headerlink" title="CNN的性质"></a>CNN的性质</h1><p>CNN具有局部平稳(i.e.与位置无关，满足平移不变形) 以及多尺度的特点。</p><p>在图像领域，数据以格子的形式分布，非常规律，对其进行处理时需要处理的是每个格子上的信号而非结构。</p><p>然而，CNN仅在欧式数据上能够发挥作用，对于图、流形等非欧式数据而言，需要进行一定的变换。</p><p>欧式数据的特点：</p><ol><li>非负</li><li>对称</li><li>满足三角不等式</li></ol><h1 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a>傅里叶变换</h1><p>在连续的空间上：</p><script type="math/tex; mode=display">h(t) = (f * g)(t) \overset{def}\Longrightarrow \int f(t)g(t - \tau) d \tau</script><p>在离散的空间上：</p><script type="math/tex; mode=display">h(x,y) = (f * g)(x,y) \overset{def}\Longrightarrow \sum_{m,n} f(x-m,y-n)g(m,n)</script><p>不同域的CNN:</p><ul><li>对于频域而言，卷积核若定义在频域，则它不是local的，对一个地方的修改会影响到全局。</li><li>对于空间域而言，在节点上定义卷积，对节点周围的邻居节点做平滑。但对于大多数节点而言，度很小，而小部分节点的度很大。</li></ul><h1 id="谱域的CNN方法"><a href="#谱域的CNN方法" class="headerlink" title="谱域的CNN方法"></a>谱域的CNN方法</h1><p>一个图可以被定义为$G = (V,E,W)$,其中$n = |V|$为节点的个数，$W \in R^{n \times n}$为权重邻接矩阵。</p><p>每个节点有$d$个feature，$X \in R^{n \times d}$ 为节点的特征矩阵。</p><p>对于在非欧式距空间中对数据进行处理，我们可以考虑两种方法：</p><ol><li>将图嵌入到欧式空间，再使用CNN对其进行处理，即embedding的方法</li><li>对CNN进行修改，使其能够用于图结构，即GCNN的方法</li></ol><p>note：embedding嵌入什么空间取决于loss的设置。此外，若是需要在图中找pattern，则embedding的方式不适用，因为其找不到结构pattern。</p><h2 id="图上的傅里叶basis"><a href="#图上的傅里叶basis" class="headerlink" title="图上的傅里叶basis"></a>图上的傅里叶basis</h2><p>图上的拉普拉斯L：对信号求导，越大越不平滑，是刻画图上平滑程度的算子。</p><script type="math/tex; mode=display">L=D-W</script><p>D为对角阵，$D_{ii} = \sum_j W_{ij}$</p><p>L为非负的，对应信号的平滑程度，当值等于0时信号平滑。</p><p>Normalized graph Laplacien:</p><script type="math/tex; mode=display">L = I - D^{- \frac{1}{2}} W D^{- \frac{1}{2}}</script><p>$I$:Identity matrix</p><p>在傅里叶变换中，利用基组使空间域映射到频域，即利用正弦波对信号进行分解。</p><p>图拉普拉斯可以被对角化为：</p><script type="math/tex; mode=display">L = U \Lambda U^T</script><p>$\{u_l\}^{n-1}_{l=0}$ : 正交特征向量的完全集<br>$\{\lambda_l\}^{n-1}_{l=0}$ : 相应的非负特征值</p><p>需要注意的是，都是正交才能进行点积。</p><p>其中$U=[u_0,…,u_{n-1}],\Lambda = diag([\lambda_0,…,\lambda_{n-1}])$</p><h2 id="图傅里叶变换"><a href="#图傅里叶变换" class="headerlink" title="图傅里叶变换"></a>图傅里叶变换</h2><p>对于一个信号$x \in R^n$,傅里叶变换定义为：</p><script type="math/tex; mode=display">\hat{x} = U^T x</script><p>傅里叶逆变换：</p><script type="math/tex; mode=display">x =  U \hat{x}</script><p>傅里叶变换中的定理:卷积在进行傅里叶变换之后会变为点积</p><p>因此，x与y的卷积可以表示为：</p><script type="math/tex; mode=display">x \ast_G y = U (( U^T x) \odot ( U^T y))</script><p>卷积的过程可以被拆解成三步：</p><ol><li>对x做傅里叶变换: $U^T x$</li><li>乘以卷积核:$g_{\theta} U^T x$</li><li>做傅里叶逆变换: $U g_{\theta} U^T x$</li></ol><p>因此卷积可以被写为：</p><script type="math/tex; mode=display">x \*_G y = U g_{\theta} U^T x</script><script type="math/tex; mode=display">x_{k+1,j} = h(\sum^{f_k}_{i=1} U F_{k,i,j} U^T x_{k,i})</script><p>$x_{k,i}$:k+h 信号</p><p>缺点：</p><ol><li>要进行特征分解</li><li>需要大量计算。U的复杂度为$O(N^2)$</li><li>不是localized</li></ol><h2 id="ChebyNet"><a href="#ChebyNet" class="headerlink" title="ChebyNet"></a>ChebyNet</h2><p>思想：参数化滤波器</p><script type="math/tex; mode=display">g_{\theta} = diag([\theta_0,...,\theta_{n-1}]) \Rightarrow g_\beta(\Lambda) = \sum^{K-1}_{k = 0} \beta_k \Lambda^k</script><p>参数由n个减少为k个($\beta_k$)</p><p>ChebyNet:</p><script type="math/tex; mode=display">x *\ast_G y = U g_\beta (\Lambda) U^T x = \sum_{k=0}^{K-1} \beta_k L^k x</script><p>U被约了，只留下了L，而L是稀疏的。<br>通过约束空间，来使使其变成local。</p><p>优点：</p><ol><li>无需特征分解</li><li>卷积核是local的</li><li>计算复杂度：$O(n^2) \rightarrow O(|E|)$</li></ol><h2 id="Graph-wavelet-neural-network-GWNN"><a href="#Graph-wavelet-neural-network-GWNN" class="headerlink" title="Graph wavelet neural network(GWNN)"></a>Graph wavelet neural network(GWNN)</h2><p>ChebyNet通过特征值矩阵$\Lambda$的多项式方程来限制图滤波器的空间来达到localized卷积：</p><script type="math/tex; mode=display">g_\theta(\Lambda) = \sum^{K-1}_{k=0} \theta_k \Lambda^k</script><p>GWNN通过使用小波基对基进行替换来达到localized图卷积的效果。</p><p>傅里叶basis $U$：</p><ul><li>稠密</li><li>非局部</li><li>高计算成本</li></ul><p>小波basis $\psi_s = U e^{\lambda_s} U^T$：</p><ul><li>稀疏</li><li>局部</li><li>低计算成本</li></ul><p>主要思想：从特征变换中剥离图卷积</p><script type="math/tex; mode=display">x_{k+1,j} = h(\sum^p_{i=1} \psi_s F_{k,i,j} \psi^{-1}_s x_{k,i}), \quad j = 1,...,q</script><p>特征变换部分：</p><script type="math/tex; mode=display">y_{k,j} = \sum^{p}_{i=1} T_{ji} x_{k,i}</script><p>图卷积部分：</p><script type="math/tex; mode=display">x_{k+1,j} = h(\psi_s F_k \psi^{-1}_s y_{k,j})</script><h1 id="空间域CNN方法"><a href="#空间域CNN方法" class="headerlink" title="空间域CNN方法"></a>空间域CNN方法</h1><h2 id="类比方法"><a href="#类比方法" class="headerlink" title="类比方法"></a>类比方法</h2><p>将卷积过程拆分成三步：</p><ol><li>确定邻居</li><li>确定邻居的顺序</li><li>参数共享（卷积核里，在定序的基础上）</li></ol><p>问题：邻居的数量不同（有的多有的少），然而卷积核的大小是固定的。\<br>解决方式：给定中心节点，确定其到其他节点的<strong>距离函数</strong>，选前TOP K个邻居。</p><h2 id="GraphSAGE"><a href="#GraphSAGE" class="headerlink" title="GraphSAGE"></a>GraphSAGE</h2><p>分为两步：</p><ol><li>以某个节点为中心对其邻居节点进行采样</li><li>做aggregate（带权平均）</li></ol><script type="math/tex; mode=display">a_v^{(k)} = AGGREGATE^{(k)}(\{h_u^{(k-1)} : U \in N(v) \})</script><script type="math/tex; mode=display">h_v^(k) = COMBINE^{(k)} (h_v^{(k-1)}, a_v^{(k)})</script><h2 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h2><script type="math/tex; mode=display">Z = f(X,A) = softmax(\hat{A} ReLU(\hat{A}XW^{(0)})) W^{(1)})</script><p>$\hat{A}$ : 邻接矩阵的变形，给定，与结构有关 \<br>$W^{(0)}, W^{(1)}$: 特征变换参数\<br>$X$ : feature</p><p>对$\hat{A}$进行参数化 $\rightarrow$ 加attention机制：</p><script type="math/tex; mode=display">\alpha_{ij} = \frac{exp(Leaky \quad ReLU(\overset{\sim}a [W \vec{h}_i ||W \vec{h}_j]))}{\sum_{k \in N_i} exp(Leaky \quad ReLU(\overset{\sim}a [W \vec{h}_i ||W \vec{h}_j]))}</script><p>本质上是求节点i和j的相似度。</p><h2 id="MoNet"><a href="#MoNet" class="headerlink" title="MoNet"></a>MoNet</h2><p>是所有空间方法的通用形式。</p><script type="math/tex; mode=display">(f*g)(x) = \sum_{j=1}^J g_j D_j (x)f</script><p>$D_j (x)$ : kernel function,在频域中为基 \<br>$g_j$:kernel,可以定义为相似度函数。整个公式看做是相似度函数的加权</p><p>谱域：显式定义变换<br>空间域：不显式定义变换</p><h1 id="Graph-pooling"><a href="#Graph-pooling" class="headerlink" title="Graph pooling"></a>Graph pooling</h1><ol><li>节点粗化</li><li>节点选择</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;CNN无法处理非欧式数据，又希望在拓扑图上有效地提取空间特征来进行机器学习。因此GCNN成为了研究重点。&lt;/p&gt;
    
    </summary>
    
    
      <category term="graph" scheme="http://yoursite.com/categories/graph/"/>
    
    
      <category term="Graph" scheme="http://yoursite.com/tags/Graph/"/>
    
      <category term="GCN" scheme="http://yoursite.com/tags/GCN/"/>
    
  </entry>
  
  <entry>
    <title>A Survey on Few-shot Learning</title>
    <link href="http://yoursite.com/2020/06/12/Overview-of-Few-shot-Learning/"/>
    <id>http://yoursite.com/2020/06/12/Overview-of-Few-shot-Learning/</id>
    <published>2020-06-12T11:44:35.000Z</published>
    <updated>2020-06-12T12:19:38.633Z</updated>
    
    <content type="html"><![CDATA[<p>最近开始研究利用少量样本进行机器学习。<a href="https://arxiv.org/abs/1904.05046v2" target="_blank" rel="noopener">Wang et al.</a> 系统性地对小样本学习的工作做了一个总结，本篇对该论文以及相关的工作进行了一个梳理。</p><a id="more"></a><h1 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h1><p><strong>Main idea:</strong> Use <strong>prior knowledge</strong> to alleviate the problem of having an unreliable empirical risk minimizer in FSL supervised learning.</p><p><a href="https://imgchr.com/i/tOlmqS" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tOlmqS.md.png" alt="tOlmqS.md.png"></a></p><h1 id="METHODS"><a href="#METHODS" class="headerlink" title="METHODS"></a>METHODS</h1><p>小样本学习的方法主要可以被归为三个方面：数据，模型，以及算法。其核心都是如何更好地利用先验知识。</p><p>从数据入手，主要是利用先验知识产生更大数量的数据；从模型入手，主要思想是利用先验知识来限制假设空间的大小，从而更快的找到最优点；从算法入手，主要思想是利用先验知识来改变搜索策略。</p><h2 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h2><p><a href="https://imgchr.com/i/tO1uy6" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1uy6.md.png" alt="tO1uy6.md.png"></a></p><p>通过数据增强小样本的方法不改变搜索空间的大小，而是通过产生数据来帮助找到最优参数。它可以被归类为以下三种方法：<br><a href="https://imgchr.com/i/tO1ZWR" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1ZWR.md.png" alt="tO1ZWR.md.png"></a></p><ol><li>Transforming Samples from $D_{train}$ \<br>该类方法通过对原训练数据的操作（如图像领域中的翻转等）进行数据增强，从而达到扩充数据的效果。</li><li>Transforming Samples from a Weakly Labeled or Unlabeled Data Set \<br>该类方法利用从训练数据中学习到的predictor对无监督或者弱监督的数据集进行标注，从而获得更大规模的数据集。</li><li>Transforming Samples from Similar Data Sets \<br>该类方法从一个相似且更大规模的数据集上迁移input-output pairs，aggregation weight通常基于样本间的相似性。</li></ol><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>Main idea: Use prior knowledge to constrain the complexity of ℋ, which results in a much smaller hypothesis space $\widetilde{H}$.</p><p><a href="https://imgchr.com/i/tO1VY9" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1VY9.md.png" alt="tO1VY9.md.png"></a></p><h3 id="Multitask-Learning"><a href="#Multitask-Learning" class="headerlink" title="Multitask Learning"></a>Multitask Learning</h3><p><strong>Multitask learning</strong> learns multiple related tasks simultaneously by exploiting both task-generic and task-specific information.</p><p>Given $C$ related tasks $T_1,…,T_C$, each $T_c$ has a dataset$D_c=\{D_{train}^c, D_{test}^c\}$.</p><p>The few-shot tasks are regarded as target tasks, and the rest as source tasks.<br>Multitask learning learns from $D_{train}^c$ to obtain $\theta_c$ for train each $T_c$.</p><h4 id="Parameter-Sharing"><a href="#Parameter-Sharing" class="headerlink" title="Parameter Sharing"></a>Parameter Sharing</h4><p><strong>Parameter Sharing</strong> directly shares some parameters among tasks.</p><p><a href="https://imgchr.com/i/tO1nQx" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1nQx.md.png" alt="tO1nQx.md.png"></a></p><h4 id="Parameter-Tying"><a href="#Parameter-Tying" class="headerlink" title="Parameter Tying"></a>Parameter Tying</h4><p><strong>Parameter Tying</strong> encourages parameters of different tasks to be similar.<br>A popular approach is by regularizing the $\theta_c$.</p><p><a href="https://imgchr.com/i/tO1mS1" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1mS1.md.png" alt="tO1mS1.md.png"></a></p><h3 id="Embedding-Learning"><a href="#Embedding-Learning" class="headerlink" title="Embedding Learning"></a>Embedding Learning</h3><p><strong>Embedding learning</strong> embeds each sample $x_i \in \mathcal{X} \subseteq R^d$ to a lower-dimensional $z_i \in \mathcal{Z} \subseteq R^m$.</p><p>It have three key components:</p><ul><li>A function $f$ which embeds test sample $x_{test} \in D_test$ to $\mathcal{Z}$</li><li>A function $g$ which embeds training sample $x_{train} \in  D_{train}$ to $\mathcal{Z}$</li><li>A similarity function $s(·,·)$ which measures the similarity between $f(x_{test})$ and $g(x_I)$ in $\mathcal{Z}$</li></ul><p><a href="https://imgchr.com/i/tO1QeO" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1QeO.md.png" alt="tO1QeO.md.png"></a></p><h4 id="Task-specific-embedding-model"><a href="#Task-specific-embedding-model" class="headerlink" title="Task-specific embedding model"></a>Task-specific embedding model</h4><p>Learn an embedding function tailored for each task, by using only information from that task.</p><h4 id="Task-invariant-i-e-general-embedding-model"><a href="#Task-invariant-i-e-general-embedding-model" class="headerlink" title="Task-invariant (i.e., general) embedding model"></a>Task-invariant (i.e., general) embedding model</h4><p>Learn a general embedding function from a large-scale data set containing sufficient samples with various outputs, and then directly use this on the new few-shot $D_{train}$  without retraining.</p><p>E.g. Meta-learning (Matching Nets, Prototypical Networks, etc.), Siamese Net, etc.</p><p><a href="https://imgchr.com/i/tO1KOK" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1KOK.md.png" alt="tO1KOK.md.png"></a></p><h4 id="Hybrid-embedding-model-encodes-both-task-specific-and-task-invariant-information"><a href="#Hybrid-embedding-model-encodes-both-task-specific-and-task-invariant-information" class="headerlink" title="Hybrid embedding model (encodes both task-specific and task-invariant information)"></a>Hybrid embedding model (encodes both task-specific and task-invariant information)</h4><p>Learn a function which takes information extracted from $D_{train}$  as input and returns an embedding which acts as the parameter for $f(·)$ .</p><p><a href="https://imgchr.com/i/tO11Te" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO11Te.md.png" alt="tO11Te.md.png"></a></p><h3 id="Learning-with-External-Memory"><a href="#Learning-with-External-Memory" class="headerlink" title="Learning with External Memory"></a>Learning with External Memory</h3><p><strong>Learning with external memory</strong> extracts knowledge from $D_{train}$, and stores it in an external memory. Each new sample $D_{test}$ is then represented by a weighted average of contents extracted from the memory. </p><p>A <strong>key-value memory</strong> is usually used in FSL. \<br>Let the memory be $M \in R^{(b \times m)}$, with each of its $b$ memory slots $M(i) \in R^m$ consisting of a key-value pair $M(i)=(M_{key}(i),M_{value}(i))$. \<br>A test sample $x_{test}$ is first embedded by an embedding function $f$, and used to query for the similar memory slots.</p><p>According to the functionality of the memory, it can be subdivided into two types.</p><ol><li>Refining Representations \<br>Put $x_{train}$  into the memory, such that the stored key-value pairs can represent $x_{test}$  more accurately.</li><li>Refining Parameters \<br>Use a memory to parameterize the embedding function $g(·)$ for a new $x_{test}$ or classification model.</li></ol><p><a href="https://imgchr.com/i/tO1lwD" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1lwD.md.png" alt="tO1lwD.md.png"></a></p><h3 id="Generative-Modeling"><a href="#Generative-Modeling" class="headerlink" title="Generative Modeling"></a>Generative Modeling</h3><p><strong>Generative modeling methods</strong> estimate the probability distribution $p(x)$ from the observed $x_i$ with the help of prior knowledge.</p><p>The observed $x$ is assumed to be drawn from some distribution $p(x;\theta)$ parameterized by $\theta$. \<br>Usually, there exists a latent variable $z \backsim p(z;\gamma)$, so that $x \backsim \int p(x|z;\theta)p(z;\gamma)dz$. \<br>The prior distribution $p(z;\gamma)$ brings in prior knowledge.</p><p>According to what the latent variable 𝑧 represents, it can be grouped into three types.</p><ol><li>Decomposable Components \<br>Samples may share some smaller decomposable components with samples from the other tasks. One then only needs to find the correct combination of these decomposable components, and decides which target class this combination belongs to.</li><li>Groupwise Shared Prior \<br>Similar tasks have similar prior probabilities, and this can be utilized.</li><li>Parameters of Inference Networks \<br>To find the best $\theta$, one has to maximize the posterior </li></ol><script type="math/tex; mode=display">p(z|x;\theta,\gamma)=\frac{p(x,z;\theta ,\gamma)}{p(x;\gamma)}=\frac{p(x|z;\theta)p(z;\gamma)}{\int p(x|z;\theta)p(z;\gamma)dz}</script><p><a href="https://imgchr.com/i/tO1tSI" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1tSI.md.png" alt="tO1tSI.md.png"></a></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ol><li><p>Multitask learning \<br><strong>Scenarios:</strong> Existing similar tasks or auxiliary tasks.\<br><strong>Limitations:</strong> Joint training of all the tasks together is required. Thus, when a new few-shot task arrives, the whole multitask model has to be trained again.</p></li><li><p>Embedding learning \<br><strong>Scenarios:</strong> A large-scale data set containing sufficient samples of various classes is available. \<br><strong>Limitations:</strong> May not work well when the few-shot task is not closely related to the other tasks. </p></li><li><p>Learning with External Memory \<br><strong>Scenarios:</strong> A memory network is available.\<br><strong>Limitations:</strong> Incurs additional space and computational costs, which increase with memory size.</p></li><li><p>Generative modeling \<br><strong>Scenarios:</strong> Performing tasks such as generation and reconstruction. \<br><strong>Limitations:</strong> High inference cost, and more difficult to derive than deterministic models. </p></li></ol><h2 id="ALGORITHM"><a href="#ALGORITHM" class="headerlink" title="ALGORITHM"></a>ALGORITHM</h2><p>The algorithm is the strategy to search in the hypothesis space $H$ for the parameter $\theta$ of the best hypothesis $h^*$.</p><p>Methods in this section use prior knowledge to influence how $\theta$ is obtained, either by:</p><ol><li>providing a good initialized parameter $\theta_0$</li><li>directly learning an optimizer to output search steps</li></ol><p>In terms of how the search strategy is affected by prior knowledge, the methods can be classified into three groups.</p><p><a href="https://imgchr.com/i/tO5Z4S" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO5Z4S.md.png" alt="tO5Z4S.md.png"></a></p><h3 id="Refining-Existing-Parameters"><a href="#Refining-Existing-Parameters" class="headerlink" title="Refining Existing Parameters"></a>Refining Existing Parameters</h3><p><strong>Refining existing parameters:</strong> An initial $\theta_0$ learned from other tasks, and is then refined using $D_{train}$ . \<br>The assumption is that $\theta_0$ captures some general structures of the large-scale data. Therefore, it can be adapted to $D$ with a few iterations.</p><p>Given the few-shot $D_{train}$ , simply fine-tuning $\theta_0$ by gradient descent may lead to overfitting. Hence, methods fine-tune $\theta_0$ by regularization to prevent overfitting. They can be grouped as follows:</p><ol><li>Early-stopping . \<br>It requires separating a validation set from D train to monitor the training procedure. Learning is stopped when there is no performance improvement on the validation set.</li><li>Selectively updating $\theta_0$ . \<br>Only a portion of $\theta_0$ is updated in order to avoid overfitting.</li><li>Updating related parts of $\theta_0$ together.\<br>One can group elements of $\theta_0$ (such as the neurons in a deep neural network), and update each group jointly with the same update information.</li><li>Using a model regression network.\<br>A model regression network captures the task-agnostic transformation which maps the parameter values obtained by training on a few examples to the parameter values that will be obtained by training on a lot of samples.</li></ol><h4 id="Aggregating-a-Set-of-Parameters"><a href="#Aggregating-a-Set-of-Parameters" class="headerlink" title="Aggregating a Set of Parameters"></a>Aggregating a Set of Parameters</h4><p>Sometimes, we do not have a suitable $\theta_0$ to start with. Instead, we have many models that are learned from related tasks.</p><p><a href="https://imgchr.com/i/tO100S" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO100S.md.png" alt="tO100S.md.png"></a></p><p>Instead of using the augmented data directly, the following methods use models (with parameters $\theta_0$’s) pre-trained from these data sets. The problem is then how to adapt them efficiently to the new task using $D_{train}$ .</p><ol><li>Unlabeled data set.\<br>One can pre-train functions from the unlabeled data to cluster and separate samples well. A neural network is then used to adapt them to the new task with the few-shot $D_{train}$.</li><li>Similar data sets. \<br>few-shot object classification can be performed by leveraging samples and classifiers from similar classes. First, it replaces the features of samples from these similar classes by features from the new class. The learned classifier is then reused, and only the classification threshold is adjusted for the new class.</li></ol><h4 id="Fine-Tuning-Existing-Parameter-with-New-Parameters"><a href="#Fine-Tuning-Existing-Parameter-with-New-Parameters" class="headerlink" title="Fine-Tuning Existing Parameter with New Parameters"></a>Fine-Tuning Existing Parameter with New Parameters</h4><p>The pre-trained $\theta_0$ may not be enough to encode the new FSL task completely. Hence, an additional parameter(s) $\delta$ is used to take the specialty of D train into account. Specifically, this strategy expands the model parameter to become $\theta = \{\theta_0,\delta\}$, and fine-tunes $\theta_0$ while learning $\delta$.</p><p><a href="https://imgchr.com/i/tO1Nlt" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1Nlt.md.png" alt="tO1Nlt.md.png"></a></p><h3 id="Refining-meta-learned-parameters"><a href="#Refining-meta-learned-parameters" class="headerlink" title="Refining meta-learned parameters"></a>Refining meta-learned parameters</h3><p>Methods in this section use meta-learning to refine the meta-learned parameter $\theta_0$.The $\theta_0$ is <strong>continuously optimized</strong> by the meta-learner according to performance of the learner.</p><p><a href="https://imgchr.com/i/tO1aOf" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1aOf.md.png" alt="tO1aOf.md.png"></a></p><p>The meta-learned $\theta_0$ is often refined by gradient descent. A representative method is the <a href="https://arxiv.org/abs/1703.03400" target="_blank" rel="noopener">ModelAgnostic Meta-Learning (MAML)</a>.</p><p><a href="https://imgchr.com/i/tX3dSA" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tX3dSA.md.png" alt="tX3dSA.md.png"></a></p><p>Recently, many improvements have been proposed for MAML, mainly along the following three aspects:</p><ol><li>Incorporating task-specific information. \<br>MAML provides the same initialization for all tasks. However, this neglects task-specific information, and is appropriate only when the set of tasks are all very similar.</li><li>Modeling the uncertainty of using a meta-learned $\theta_0$.\<br>The ability to measure this uncertainty provides hints for active learning and further data collection . There are works that consider uncertainty for the meta-learned $\theta_0$, uncertainty for the task-specific $\phi_s$, and uncertainty for class n’s class-specific parameter$\phi_{s,n}$.</li><li>Improving the refining procedure.\<br>Refinement by a few gradient descent steps may not be reliable. Regularization can be used to correct the descent direction.</li></ol><h3 id="Learning-the-optimizer"><a href="#Learning-the-optimizer" class="headerlink" title="Learning the optimizer"></a>Learning the optimizer</h3><p>Instead of using gradient descent, methods in this section learns an optimizer which can directly output the update ($\sum_{i=1}^t\Delta\theta^{i-1}$). There is then no need to tune the stepsize $\alpha$ or find the search direction, as the learning algorithm does that automatically.</p><p><a href="https://imgchr.com/i/tO1wm8" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1wm8.md.png" alt="tO1wm8.md.png"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近开始研究利用少量样本进行机器学习。&lt;a href=&quot;https://arxiv.org/abs/1904.05046v2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Wang et al.&lt;/a&gt; 系统性地对小样本学习的工作做了一个总结，本篇对该论文以及相关的工作进行了一个梳理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="survey" scheme="http://yoursite.com/categories/survey/"/>
    
    
      <category term="Few-shot Learning" scheme="http://yoursite.com/tags/Few-shot-Learning/"/>
    
      <category term="Transfer Learning" scheme="http://yoursite.com/tags/Transfer-Learning/"/>
    
      <category term="Meta Learning" scheme="http://yoursite.com/tags/Meta-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Multi-Task Identiﬁcation of Entities, Relations, and Coreference for Scientiﬁc Knowledge Graph Construction</title>
    <link href="http://yoursite.com/2019/09/24/Multi-Task-Identi%EF%AC%81cation-of-Entities-Relations-and-Coreference-for-Scienti%EF%AC%81c-Knowledge-Graph-Construction/"/>
    <id>http://yoursite.com/2019/09/24/Multi-Task-Identi%EF%AC%81cation-of-Entities-Relations-and-Coreference-for-Scienti%EF%AC%81c-Knowledge-Graph-Construction/</id>
    <published>2019-09-24T09:43:37.000Z</published>
    <updated>2020-06-05T02:39:53.097Z</updated>
    
    <content type="html"><![CDATA[<p>本文提出了一种基于共享span表示进行多任务分类的框架（实体分类、关系分类、共指消解），将科学文献摘要抽取成知识图。</p><p>Accepted by: EMNLP 2018<br>Paper link：<a href="http://ssli.ee.washington.edu/~luanyi/YiLuan_files/EMNLP2018_YL_sciIE.pdf" target="_blank" rel="noopener">http://ssli.ee.washington.edu/~luanyi/YiLuan_files/EMNLP2018_YL_sciIE.pdf</a></p><a id="more"></a><h1 id="Challenge"><a href="#Challenge" class="headerlink" title="Challenge"></a>Challenge</h1><ul><li>尽管搜索引擎取得了进步，但仍然很难确定新技术及其与之前技术存在的关系</li><li>科学文本的注释需要领域专业知识，这使得注释成本高昂并限制了资源</li><li>大多数关系提取系统都是针对句内关系而设计的，但是从科学文章中提取信息需要提取句子之间的关系</li></ul><h1 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h1><ul><li>开发了一个统一的学习模型（科学信息提取器框架， SCIIE），用于提取科学实体、关系和共指消解</li><li>创建了SCIERC数据库，包含科学名词、关系类别以及共指链接的标注（500个标注的科学摘要）<ul><li>6种实体</li><li>7种关系</li><li>共指链接在实体间的标注</li></ul></li></ul><h1 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h1><p>该论文提出了SCIERC数据集，包括了500个科学摘要，标记了其中的实体类型、实体间的关系以及共指关系。</p><p>下载链接：<a href="http://nlp.cs.washington.edu/sciIE/" target="_blank" rel="noopener">http://nlp.cs.washington.edu/sciIE/</a></p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3VrdmRKQS5wbmc?x-oss-process=image/format,png#pic_center" alt="annotation"></p><center>Fig 1.标注实例.</center><h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><h2 id="主要思想"><a href="#主要思想" class="headerlink" title="主要思想"></a>主要思想</h2><p>在低级别任务间共享参数，将三个任务看成共享span表示的多项分类问题</p><h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>输入：单词序列 $D = {w_1, …,w_n}$;</p><p>所有可能的句内词序列span $S = {s_1, … , s_N}$</p><p>输出：所有Span(即S)的实体类型E; </p><p>$S \times S$的关系R; </p><p>S中所有span的共指关系C</p><h2 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h2><p>将多任务学习定义为条件概率分布: $P(E,R,C|D)$</p><p>为了高效地训练和推理，将该分部拆分成：<br>$P(E,R,C|D) = P(E,R,C,S|D) = \prod^N_{i=1} P(e_i |D) P(c_i | D)\prod^N_{j=1}P(r_{ij}|D)$</p><p>其中每个随机变量的条件概率是独立标准化的：</p><script type="math/tex; mode=display">P(e_i= e|D) = \frac{exp(\Phi_E (e,s_i))} {\sum_{e' \in L_E} exp(\Phi_E(e',s_i))}</script><script type="math/tex; mode=display">P(r_{ij}= r|D) = \frac{exp(\Phi_R (r,s_i,s_j))} {\sum_{r' \in L_R} exp(\Phi_R(r',s_i,s_j))}</script><script type="math/tex; mode=display">P(c_i= j|D) = \frac{exp(\Phi_C (s_i,s_j))} {\sum_{j' \in \{1,...,i-1,\epsilon \}} exp(\Phi_E(e',s_i))}</script><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3VrdmFpZC5wbmc?x-oss-process=image/format,png#pic_center" alt="Overview"></p><center>Fig 2. 多任务设置，三个任务被看做是顶层共享Span表示的分类问题.</center><h2 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h2><p>给定一组所有文档D，模型损失函数被定义为所有三个任务的负对数似然丢失的加权和：</p><script type="math/tex; mode=display">-\sum_{(D,R^*,E^*,C^*) \in D} \{\lambda_E logP(E^* |D) + \lambda_R logP(R^*|D) + \lambda_C log P(C^*|D)\}</script><p>$R^<em>, E^</em>, C^<em>$ 为goal。<br>令$C_i^</em>$ 为span i里所有正确的祖先。即：</p><script type="math/tex; mode=display">log P(C^*|D = \sum_{i=1...N}log\sum_{c \in C^*_i} P(c|D))</script><h2 id="打分结构"><a href="#打分结构" class="headerlink" title="打分结构"></a>打分结构</h2><ul><li><p>在共享跨度表示g上使用前馈神经网络（FFNN）来计算一组跨度和成对跨度的分数。</p><ul><li>$\phi_e(s_i)$:一个跨度$s_i$有一个实体类型e的可能性；        </li><li>$\phi_{mr}(s_i)$跨度$s_i$在一个关系r中被提到的可能性；       </li><li>$\phi_{mc}(s_i)$跨度$s_i$在一条共指链接中被提到的可能性</li><li>$\phi_r(s_i,s_j)$两个跨度与一个关系相结合的可能性；</li><li>$\phi_c(s_i,s_j)$两个跨度与一条共指链接相结合的可能性</li><li>$g_i$：$s_i$的向量表示 (ELMo)：连接来自BiLSTM的输出的$s_i$的左端点和右端点，基于注意力的软词条，嵌入span的宽度特征</li><li>span打分以及成对的span打分的计算方式：<script type="math/tex; mode=display">\phi_x(s_i) = w_x \dot FFNN_x(g_i)\phi_y(s_i,s_j)=w_y \dot FFNN_y([g_i,g_j,g_i \odot g_j])</script></li></ul></li><li>这些分数被用于计算最终打分:<script type="math/tex; mode=display">\Phi_E (e,s_i) = \phi_e(s_i)</script><script type="math/tex; mode=display">\Phi_R (r,s_i,s_j) = \phi_{mr}(s_i) + \phi_{mr}(s_j) + \phi_r(s_i,s_j)</script><script type="math/tex; mode=display">\Phi_C (s_i,s_j) = \phi_{mc}(s_i) + \phi_{mc}(s_j) + \phi_c(s_i,s_j)</script></li></ul><h2 id="推理和剪枝"><a href="#推理和剪枝" class="headerlink" title="推理和剪枝"></a>推理和剪枝</h2><p>使用波束搜索，根据打分排序减少训练和测试中成对的span的数量以将计算复杂度降低到$O(n)$.</p><p>使用$B_C$修剪共指消解任务中的span，使用$B_R$修剪关系抽取任务中的span。</p><p>使用span score $\phi_{mc}$和 $\phi_{mr}$对波束中的span进行排序，波束的大小用$\lambda_Cn$和$\lambda_Rn$进行约束。span的最大宽度为W。</p><h1 id="KG-Construction"><a href="#KG-Construction" class="headerlink" title="KG Construction"></a>KG Construction</h1><p>为了构建整个语料库中的知识图，先将SCIIE用于单个文档（摘要），再将多个文档中的实体和关系集成。</p><ul><li><p>结点（实体）抽取</p><ul><li><p>句子被启发式地标准化</p><ul><li>利用共指链接，将不通用词汇替换为通用词汇</li><li>采用字符长度最长的实体名称（使用全名替代首字母缩略）</li><li>使用单数标准化所有复数</li></ul></li><li><p>计算整个语料库中的实体出现频率</p><ul><li>出现频率&gt;k的实体为它分配结点</li><li>将频繁出现的、为子字符串的剩余实体进行合并</li></ul></li></ul></li><li><p>边（关系）分配</p><ul><li>在整个语料库中计算一对实体间的关系出现频率，选择频率最大的关系</li></ul></li></ul><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3VrdnRkZS5wbmc?x-oss-process=image/format,png#pic_center" alt="知识图谱构建过程"></p><center>Fig 3. 知识图谱的构建过程.</center><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3VrdndSSS5wbmc?x-oss-process=image/format,png#pic_center" alt="自动构建的知识图"></p><center>Fig 4. 自动构建的知识图.</center><h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3Vrdk5JSC5wbmc?x-oss-process=image/format,png#pic_center" alt="RESULT"></p><center>Table 1. 三个任务上与其他系统的性能对比.</center><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3VrdkRRUC5wbmc?x-oss-process=image/format,png#pic_center" alt="ablation"></p><center>Table 2. 多任务学习的消融研究.</center><h1 id="KG-Analysis"><a href="#KG-Analysis" class="headerlink" title="KG Analysis"></a>KG Analysis</h1><h2 id="科学趋势分析"><a href="#科学趋势分析" class="headerlink" title="科学趋势分析"></a>科学趋势分析</h2><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3VrdjB6dC5wbmc?x-oss-process=image/format,png#pic_center" alt="科学趋势分析"></p><center>Fig 5. 关键词 神经网络 在NLP\speech\CV领域的历史研究趋势.Y轴：在该任务中使用神经网络的论文与使用其他论文的比例.</center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文提出了一种基于共享span表示进行多任务分类的框架（实体分类、关系分类、共指消解），将科学文献摘要抽取成知识图。&lt;/p&gt;
&lt;p&gt;Accepted by: EMNLP 2018&lt;br&gt;Paper link：&lt;a href=&quot;http://ssli.ee.washington.edu/~luanyi/YiLuan_files/EMNLP2018_YL_sciIE.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://ssli.ee.washington.edu/~luanyi/YiLuan_files/EMNLP2018_YL_sciIE.pdf&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper-reading" scheme="http://yoursite.com/categories/paper-reading/"/>
    
    
      <category term="knowledge graph" scheme="http://yoursite.com/tags/knowledge-graph/"/>
    
      <category term="multi-task learning" scheme="http://yoursite.com/tags/multi-task-learning/"/>
    
      <category term="paper-reading" scheme="http://yoursite.com/tags/paper-reading/"/>
    
  </entry>
  
  <entry>
    <title>Overview of Crawler Technology</title>
    <link href="http://yoursite.com/2019/03/22/Overview-of-Crawler-Technology/"/>
    <id>http://yoursite.com/2019/03/22/Overview-of-Crawler-Technology/</id>
    <published>2019-03-22T11:44:35.000Z</published>
    <updated>2019-03-22T12:17:57.772Z</updated>
    
    <content type="html"><![CDATA[<p>大致记录了一下爬虫的整体思想和一些常用的库方便日后项目中进行查阅。本文的主要内容整理自崔庆才的爬虫教程。<br><a id="more"></a></p><h2 id="爬虫基本流程"><a href="#爬虫基本流程" class="headerlink" title="爬虫基本流程"></a>爬虫基本流程</h2><ol><li>发起请求<br>通过HTTP库向目标站点发起请求，即发送一个request，请求可以包含额外的header等信息，等待服务器响应</li><li>获取响应内容<br>如果服务器能正常响应，会得到一个response，response的内容便是所要获取的页面内容，类型可能有HTML,Json字符串，二进制数据（如图片视频）等类型。</li><li>解析内容<br>得到的内容可能是HTML，可以用正则表达式、网页解析库进行解析。可能是Json，可以直接转为Json对象解析，可能是二进制数据，可以做保存或者进一步的处理</li><li>保存数据<br>保存形式多样，可以存为文本，也可以保存至数据库，或者保存特定格式的文件</li></ol><h2 id="Request-和-Response"><a href="#Request-和-Response" class="headerlink" title="Request 和 Response"></a>Request 和 Response</h2><h3 id="Request"><a href="#Request" class="headerlink" title="Request"></a>Request</h3><ol><li>请求方式<br>主要有<strong>GET、POST</strong>两种类型，另外还有HEAD、PUT、DELETE、OPTIONS等<br>GET和POST的区别：<br>get：直接输入URL回车访问<br>post：需要构建表单，点击表单提交，请求参数不会包含在URL后</li><li>请求URL<br>URL全称统一资源定位符，如一个网页文档、一张图片、一个视频都可以用URL唯一来确定。<blockquote><p>在渲染过程中，浏览器会根据图片的URL重新发送请求，渲染出图片</p></blockquote></li><li>请求头<br>包含请求时的头部信息，如User-Agent、Host、Cookies等信息\<br>用于服务器判断配置信息</li><li>请求体<br>请求时额外携带的数据，如表单提交时的表单数据</li></ol><h3 id="Response"><a href="#Response" class="headerlink" title="Response"></a>Response</h3><ol><li>响应状态<br>判断网页响应状态\<br>e.g.状态码：\<br>200 成功\<br>301 跳转 \<br>404 找不到服务器\<br>505 服务器错误</li><li>响应头<br>如服务类型、内容长度、服务器信息、设置Cookie等等。</li><li>响应体<br>最主要的部分，包含了请求资源的内容，如网页HTML、图片二进制数据等。</li></ol><h2 id="能抓取的数据"><a href="#能抓取的数据" class="headerlink" title="能抓取的数据"></a>能抓取的数据</h2><ol><li>网页文本<br>如HTML文档、Json格式文本等。</li><li>图片<br>获取到的是二进制文件，保存为图片格式</li><li>视频<br>同为二进制文件，保存为视频格式即可。</li><li>其他<br>只要是能获取到的都能抓取</li></ol><h2 id="解析方式"><a href="#解析方式" class="headerlink" title="解析方式"></a>解析方式</h2><ol><li>直接处理</li><li>Json解析</li><li>正则表达式</li><li>BeautifulSoup</li><li>PyQuery</li><li>XPath</li></ol><h2 id="怎样保存数据"><a href="#怎样保存数据" class="headerlink" title="怎样保存数据"></a>怎样保存数据</h2><ol><li>文本<br>纯文本、Json、Xml等</li><li>关系型数据库<br>如MySQL、Oracle、SQL Server等具有结构化表结构形式存储。</li><li>非关系型数据库<br>如MongoDB、Redis等Key-Value形式存储。</li><li>二进制文件<br>如图片、视频、音频等等直接保存成特定形式即可。</li></ol><h1 id="Urllib库基本使用"><a href="#Urllib库基本使用" class="headerlink" title="Urllib库基本使用"></a>Urllib库基本使用</h1><h2 id="什么是Urllib"><a href="#什么是Urllib" class="headerlink" title="什么是Urllib"></a>什么是Urllib</h2><p>Python内置的HTTP请求库\<br>urllib.request 请求模块\<br>urllib.error 异常处理模块\<br>urllib.parse url解析模块(工具模块)\<br>urllib.robotparser robots.txt解析模块</p><h2 id="用法讲解"><a href="#用法讲解" class="headerlink" title="用法讲解"></a>用法讲解</h2><h3 id="Request-1"><a href="#Request-1" class="headerlink" title="Request"></a>Request</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urllib.request.urlopen(url, data=<span class="literal">None</span>, [timeout, ]*, cafile=<span class="literal">None</span>, capath=<span class="literal">None</span>, cadefault=<span class="literal">False</span>, context=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://python.org'</span>)</span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将hello以post的形式传递，完成一个post的请求；若不加data则以get的形式发送</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line">data = bytes(urllib.parse.urlencode(&#123;<span class="string">'word'</span>:<span class="string">'hello'</span>&#125;).encoding=<span class="string">'utf8'</span>)</span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://httpbin.org/post'</span>,data=data)</span><br><span class="line">print(response.read())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在设置时间内没有得到响应的话会抛出异常；http://httpbin.org/get会返回请求时的一些参数，以json形式</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://httpbin.org/get'</span>,timeout=<span class="number">1</span>)</span><br><span class="line">print(response.read())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将异常时间设为0.1秒，对异常进行捕获</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = urllib.request.urlopen(<span class="string">'http://httpbin.org/get'</span>,timeout=<span class="number">0.1</span>)</span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">if</span> isinstance(e.reason,socket.timeout):\\将错误的原因进行判断</span><br><span class="line">        print(<span class="string">'TIME OUT'</span>)</span><br></pre></td></tr></table></figure><h3 id="Response-1"><a href="#Response-1" class="headerlink" title="Response"></a>Response</h3><h4 id="响应类型"><a href="#响应类型" class="headerlink" title="响应类型"></a>响应类型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://www.python.org'</span>)</span><br><span class="line">print(type(response))</span><br></pre></td></tr></table></figure><h4 id="状态码、响应头"><a href="#状态码、响应头" class="headerlink" title="状态码、响应头"></a>状态码、响应头</h4><p>是判断响应是否成功的重要标志<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://www.python.org'</span>)</span><br><span class="line">print(response.status)</span><br><span class="line">print(response.getheaders())</span><br><span class="line">print(response.getheaders(<span class="string">'Server'</span>))    <span class="comment">#获取一个特定的响应头(Server)</span></span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://www.python.org'</span>)</span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))    <span class="comment">#read是获得一个响应体的内容</span></span><br></pre></td></tr></table></figure><br>若要发送更为复杂的request<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加入新的headers</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(<span class="string">'http://www.python.org'</span>)</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure></p><h3 id="Handler"><a href="#Handler" class="headerlink" title="Handler"></a>Handler</h3><p>相当于辅助工具，帮助我们进行其他的操作</p><h4 id="设置代理"><a href="#设置代理" class="headerlink" title="设置代理"></a>设置代理</h4><p>设置代理可以切换本地的ip地址使不被封<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">proxy_handler = urllib.request.ProxyHandler(&#123;</span><br><span class="line">    <span class="string">'http'</span>:<span class="string">'http://127.0.0.1:9743'</span>,</span><br><span class="line">    <span class="string">'https'</span>:<span class="string">'https://127.0.0.1:9743'</span>,</span><br><span class="line">&#125;)</span><br><span class="line">opener = urllib.request.build_opener(proxy_handler)</span><br><span class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">print(response.read())</span><br></pre></td></tr></table></figure></p><h4 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h4><p>用来维持登录状态<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> http.cookiejar,urllib.request</span><br><span class="line"></span><br><span class="line">cookie = http.cookiejar.CookieJar() <span class="comment">#cookie创建为对象</span></span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> cookie: <span class="comment">#对cookie遍历</span></span><br><span class="line">    print(item.name+<span class="string">"="</span>+item.value)</span><br></pre></td></tr></table></figure><br>可将Cookie保存成文本文件，若cookie没有失效的话可以从文件中读出cookie，请求时附加cookie信息来保持登录状态。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将cookie保存为txt文件</span></span><br><span class="line"><span class="keyword">import</span> http.cookiejar,urllib.request</span><br><span class="line"></span><br><span class="line">filename = <span class="string">"cookie.txt"</span></span><br><span class="line">cookie = http.cookiejar.MozillaCookieJar(filename)</span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">cookie.save(ignore_discard=<span class="literal">True</span>,ignore_expires=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br>还有一种保存方式<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用文本文件的形式把cookie存储，然后读取出来，然后把cookie再次放到request里面，请求出了这个网页，这样请求的结果就是登陆后才能看到的网页内容</span></span><br><span class="line"><span class="keyword">import</span> http.cookiejar,urllib.request</span><br><span class="line"></span><br><span class="line">cookie = http.cookiejar.LWPCookieJar()</span><br><span class="line">cookie.load(<span class="string">'cookie.txt'</span>,ignore_discard=<span class="literal">True</span>,ignore_expires=<span class="literal">True</span>)</span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br><span class="line">filename = <span class="string">"cookie.txt"</span></span><br></pre></td></tr></table></figure></p><h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#请求一个不存在的网页</span></span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,error</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(<span class="string">'http://cuiqingcai.com/index.htm'</span>)</span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason) <span class="comment">#捕捉的是URL的异常</span></span><br></pre></td></tr></table></figure><p>具体可以捕捉哪些异常，see:<a href="https://docs.python.org/3/library/urllib.html" target="_blank" rel="noopener">https://docs.python.org/3/library/urllib.html</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#请求一个不存在的网页</span></span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,error</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(<span class="string">'http://cuiqingcai.com/index.htm'</span>)</span><br><span class="line"><span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason,e.code,e.headers,sep=<span class="string">'\n'</span>) </span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason) </span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">'Request Successfully'</span>)</span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,error</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(<span class="string">'http://cuiqingcai.com/index.htm'</span>,timeout = <span class="number">0.01</span>)</span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(type(e.reason))</span><br><span class="line">    <span class="keyword">if</span> isinstance(e.reason,socket.timeout):</span><br><span class="line">        print(<span class="string">'TIME OUT'</span>)</span><br></pre></td></tr></table></figure></p><h3 id="URL解析"><a href="#URL解析" class="headerlink" title="URL解析"></a>URL解析</h3><h4 id="urlparse"><a href="#urlparse" class="headerlink" title="urlparse"></a>urlparse</h4><p>传入一个URL，然后将URL进行分割，分割成几个部分，然后将各个部分依次进行复制\<br>所有URL都可以按标准的结构划分<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urllib.parse.urlparse(urlstring, scheme=<span class="string">''</span>, allow_fragments=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line"></span><br><span class="line">result = urlparse(<span class="string">'http://www.baidu.com/index.html'</span>)</span><br><span class="line">print(type(result),result)</span><br></pre></td></tr></table></figure><br>若没有协议类型，则默认为https类型<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line"></span><br><span class="line">result = urlparse(www.baidu.com/index.html<span class="string">',scheme="https")</span></span><br><span class="line"><span class="string">print(result)</span></span><br></pre></td></tr></table></figure><br>若allow_fragments=False，则其内容将拼接到前面的内容中（成为path或query或params）</p><h4 id="urlunparse"><a href="#urlunparse" class="headerlink" title="urlunparse"></a>urlunparse</h4><p>urlparse的反函数，将url进行拼接<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlunparse</span><br><span class="line"></span><br><span class="line">data = [<span class="string">'http'</span>,<span class="string">'www.baidu.com'</span>,<span class="string">'index.html'</span>,<span class="string">'user'</span>,<span class="string">'a=6'</span>,<span class="string">'comment'</span>]</span><br><span class="line">print(urlunparse(data))</span><br></pre></td></tr></table></figure></p><h4 id="urljoin"><a href="#urljoin" class="headerlink" title="urljoin"></a>urljoin</h4><p>用于拼接url，若前面的url和后面的url不同，后面的字段会覆盖前面的字段</p><h4 id="urlencode"><a href="#urlencode" class="headerlink" title="urlencode"></a>urlencode</h4><p>将字典对象转变为url请求参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'name'</span>:<span class="string">'germey'</span>,</span><br><span class="line">    <span class="string">'age'</span>:<span class="number">22</span></span><br><span class="line">&#125;</span><br><span class="line">base_url = <span class="string">'http://www.baidu.com?'</span></span><br><span class="line">url = base_url + urlencode(params)</span><br><span class="line">print(url)</span><br></pre></td></tr></table></figure></p><h3 id="robotparser"><a href="#robotparser" class="headerlink" title="robotparser"></a>robotparser</h3><p>用来解析robot.txt文件</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大致记录了一下爬虫的整体思想和一些常用的库方便日后项目中进行查阅。本文的主要内容整理自崔庆才的爬虫教程。&lt;br&gt;
    
    </summary>
    
    
      <category term="crawler" scheme="http://yoursite.com/categories/crawler/"/>
    
    
      <category term="Crawler" scheme="http://yoursite.com/tags/Crawler/"/>
    
  </entry>
  
  <entry>
    <title>Overview of Knowledge Graph</title>
    <link href="http://yoursite.com/2019/03/22/Knowledge-Graph-Overview/"/>
    <id>http://yoursite.com/2019/03/22/Knowledge-Graph-Overview/</id>
    <published>2019-03-22T11:26:34.000Z</published>
    <updated>2019-03-22T12:17:29.517Z</updated>
    
    <content type="html"><![CDATA[<p>在计算机世界中，节点和边的符号通过“符号具化（symbol grounding）”表征物理世界和认知世界中的对象，并作为不同个体对认知世界中信息和知识进行描述和交换的桥梁。这种使用统一形式描述的知识描述框架便于知识的分享与利用。</p><a id="more"></a><h2 id="知识图谱的类型"><a href="#知识图谱的类型" class="headerlink" title="知识图谱的类型"></a>知识图谱的类型</h2><ul><li>语言知识图谱<br>主要是存储人类语言方面的知识，其中比较典型是英文词 汇知识图谱WordNet，它由同义词集和描述同义词集之间的关系构成。</li><li>常识知识图谱<br>主要有 Cyc和 ConceptNet等。其中 Cyc 由大量实体和 关系以及支持推理的常识规则构成；ConceptNet 由大量概念以及描述 它们之间关系的常识构成。</li><li>语言认知知识图谱<br>中文知网词库HowNet是一种典型的语言认知知识图谱（语言认知知识与常识知识区别不大，因为语言是人类表达和交换信息的主要载体），HowNet致力于描述认知世界中人们对词语概念的理解，基于词语义原，揭示词语的更小语义单元的含义。</li><li>领域知识图谱<br>针对特定领域构建的知识图谱，专门为特定的领域服务， 例如：医学知识图谱 SIDER(Side Effect Resource) ，电影知识图谱 IMDB (Internet Movie Database)，音乐知识图谱MusicBrainz等，这些知识图谱在各自的领域都有着广泛的应用。</li><li>百科知识图谱<br>主要以 Linked Open Data (LOD)项目支持的开放知识 图谱为核心，主要有 Freebase、DBpedia、YAGO和Wikidata等，它们在信息检索、问答系统等任务中有着重要应用。</li></ul><h2 id="知识图谱的生命周期"><a href="#知识图谱的生命周期" class="headerlink" title="知识图谱的生命周期"></a>知识图谱的生命周期</h2><h3 id="知识体系构建"><a href="#知识体系构建" class="headerlink" title="知识体系构建"></a>知识体系构建</h3><p>指采用什么样的方式表达知识，其核心是构建一个本体对目 标知识进行描述。   </p><p><strong>输入</strong>：领域（医疗、金融…）、应用场景<br><strong>输出</strong>：领域知识本体<br><strong>关键技术</strong>：Ontology Engineering</p><p>作为语义网的应用，知识图谱的知识建模采用语义网的知 识建模方式，分为概念、关系、概念关系三元组三个层次，并利用<strong>资源描述框架(RDF</strong>)进行描述。</p><p>RDF 的基本数据模型包括了三个对象类型：  </p><ul><li>资源<br>能够使用RDF表示的对象称之为资源，包括互联网上的实体、事件和 概念等。</li><li>谓词 (Predicate)<br>主要描述资源本身的特征和资源之间的关系。每一个谓词可以定义元知识，例如，谓词的头尾部数据值的类型（如定义域和值域）、谓词与其他谓词的关系（如逆关系）。</li><li>陈述 (Statements)<br>一条陈述包含三个部分，通常称之为RDF三元组&lt;主体(subject)，谓词(predicate)，宾语(object)&gt;。其中主体是被描述的资源，谓词可以表示主体的属性，也可以表示主体和宾语之间关系。当表示属性时，宾语就是属性值；当表示关系时，宾语也是一个资源。</li></ul><h3 id="知识获取"><a href="#知识获取" class="headerlink" title="知识获取"></a>知识获取</h3><p>知识获取目标是从海量的文本数据中通过信息抽取的方式获 取知识，其方法根据所处理数据源的不同而不同。</p><p>知识图谱中数据的主要来源有：</p><ul><li>结构化数据<br>置信度高，规模小，缺乏个性化的属性信息</li><li>半结构化数据<br>置信度高，规模较大，个性化信息，形式多样，含有噪声</li><li>非结构化文本数据  <ul><li>纯文本<br>置信度低，复杂多样，规模大</li></ul></li></ul><p><strong>输入</strong>：领域知识本体；海量数据：文本、垂直站点、百科<br><strong>输出</strong>：领域知识（实体集合，实体关系/属性）<br><strong>主要技术</strong>：信息抽取；文本挖掘</p><h4 id="实体识别"><a href="#实体识别" class="headerlink" title="实体识别"></a>实体识别</h4><p>实体识别任务的目标是从文本中识别实体信息。早期有关实体识别的研究主要是针对命名实体的识别。在知识图谱领域，从文本中识别实体不仅仅局限于命名实体 ，还包括其他类别的实体，特别是领域实体。与实体识别相关的任务是实体抽取。</p><h4 id="实体消歧"><a href="#实体消歧" class="headerlink" title="实体消歧"></a>实体消歧</h4><p>目标是消除指定实体的歧义。实体消歧对于知识图谱构建和应用有着重要的作用，也是建立语言表达和知识图谱联系的关键环节。从技术路线上划分，实体消歧任务可以分为<em>实体链接</em>和<em>实体聚类</em>两种类型。</p><h4 id="关系抽取"><a href="#关系抽取" class="headerlink" title="关系抽取"></a>关系抽取</h4><p>目标是获取两个实体之间的语义关系。</p><p>语义关系可以是一元关系（例如实体的类型），也可以是二元关系（例如实体的属性）甚至是更高阶的关系。在现有知识图谱中，所处理的语义关系通常指的是一元关系和二元关系。</p><p>根据抽取目标的不同，关系抽取任务可以分为：</p><ul><li>关系分类任务：判别一句话中两个指定实体之间的语义关系。</li><li>属性抽取任务：在给定一个实体以及一个预定义关系的条件下，抽取另外一个实体。</li><li>关系实例抽取任务：给定关系类型，抽取满足该关系的实例数据。</li></ul><h4 id="事件抽取"><a href="#事件抽取" class="headerlink" title="事件抽取"></a>事件抽取</h4><p>目标是从描述事件信息的文本中抽取出用户感兴趣的事件信息并以结构化的形式呈现出来。</p><p>事件是发生在某个特定的时间点或时间段、某个特定的地域范围内，由一个或者多个角色参与的，一个或者多个动作组 成的事情或者状态的改变。</p><p>现有知识图谱大多以实体和实体之间的关系为核心，缺乏事件知识。事件知识能弥补现有以实体和实体关系为核心的知识图谱知识表达能力不足的问题，是构建知识图谱不可或缺的技术。事件结构本身的复杂性以及自然语言表达的歧义性和灵活性 ，对事件抽取提出了很大的挑战。</p><p>根据抽取方法的不同，已有的事件抽取方法可以分为</p><ul><li>基于模式匹配的事件抽取</li><li>基于机器学习的事件抽取</li></ul><h3 id="知识融合"><a href="#知识融合" class="headerlink" title="知识融合"></a>知识融合</h3><p>对不同来源、不同语言或不同结构的知识进行融合， 从而对于已有知识图谱进行补充、更新和去重。</p><p><strong>输入</strong>：抽取出来的知识；现有知识库；知识本体<br><strong>输出</strong>：统一知识库；知识置信度<br><strong>关键技术</strong>：Ontology Matching；Entity Linking</p><p>从融合的对象看：</p><ul><li>知识体系的融合：两个或多个异构知识体系进行融合，即对相同的 类别、属性、关系进行映射。</li><li>实例的融合：对于两个不同知识图谱中的实例（实体实例、关系实例）进行融合，包括不同知识体系下的实例、不同语言的实例。</li></ul><p>从融合的知识图谱类型看：</p><ul><li>竖直方向的融合：融合（较）高层通用本体与（较）底层领域本体 或实例数据</li><li>水平方向的融合：融合同层次的知识图谱，实现实例数据的互补。</li></ul><h3 id="知识存储和查询"><a href="#知识存储和查询" class="headerlink" title="知识存储和查询"></a>知识存储和查询</h3><p>因为目前知识图谱大多是基于图的数据结构，它的存储方式 主要有两种形式：</p><ul><li>RDF 格式存储：以三元组的形式存储数据</li><li>图数据库 (Graph Database)</li></ul><p><strong>输入</strong>：大规模知识库知识<br><strong>输出</strong>：知识库存储和查询服务<br><strong>主要技术</strong>：知识表示；知识查询语言；存储/检索引擎</p><h3 id="知识推理"><a href="#知识推理" class="headerlink" title="知识推理"></a>知识推理</h3><p>由于处理数据的不完备性，知识图谱中肯定存在知识缺失现象（包括实体缺失、关系缺失）。我们也很难利用抽取或者融合的方法对于缺失的知识进行补齐。因此，需要采用推理的手段发现已有知识中隐含的知识。</p><p>目前知识推理的研究主要集中在针对知识图谱中缺失关系的补足，即挖掘两个实体之间隐含的语义关系。所采用的方法可以分为两种：</p><ul><li>基于传统逻辑规则的方法进行推理：研究热点在于如何自动学习推理规则，以及如何解决推理过程中的规则冲突问题。</li><li>基于表示学习的推理：即采用学习的方式，将传统推理过程转化为基于分布式表示的语义向量相似度计算任务。这类方法优点是容错率高、可学习，缺点也显而易见，即不可解释，缺乏语义约束。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在计算机世界中，节点和边的符号通过“符号具化（symbol grounding）”表征物理世界和认知世界中的对象，并作为不同个体对认知世界中信息和知识进行描述和交换的桥梁。这种使用统一形式描述的知识描述框架便于知识的分享与利用。&lt;/p&gt;
    
    </summary>
    
    
      <category term="knowledge graph" scheme="http://yoursite.com/categories/knowledge-graph/"/>
    
    
      <category term="Knowledge Graph" scheme="http://yoursite.com/tags/Knowledge-Graph/"/>
    
  </entry>
  
  <entry>
    <title>Algorithm Design and Analysis - Dynamic programming</title>
    <link href="http://yoursite.com/2018/10/18/Algorithm-Design-and-Analysis-Dynamic-programming/"/>
    <id>http://yoursite.com/2018/10/18/Algorithm-Design-and-Analysis-Dynamic-programming/</id>
    <published>2018-10-18T13:52:10.000Z</published>
    <updated>2019-03-22T12:17:02.694Z</updated>
    
    <content type="html"><![CDATA[<p>Main message:</p><ol><li>把子问题的求解想象成多步求解过程</li><li>子问题的最优解可以组合成原问题的最优解</li><li>Programming：tabular可以被用于避免子问题的重复计算</li></ol><a id="more"></a><p>联动： <a  href ="http://imjiawen.com/2018/08/14/Dynamic-programming-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AE%97%E6%B3%95/#more">Dynamic Programming 动态规划算法</a></p><h1 id="Dynamic-programming-VS-Divide-and-conquer"><a href="#Dynamic-programming-VS-Divide-and-conquer" class="headerlink" title="Dynamic programming VS. Divide-and-conquer"></a>Dynamic programming VS. Divide-and-conquer</h1><p>动态规划算法一般被用于解决优化问题。需满足以下几个特点：</p><ol><li>原问题可以被分解成更小的子问题</li><li>具有最优子结构性质，即最优解可以通过结合子问题的最优解得到。</li></ol><p>与通用的分治法框架不同，动态规划算法通常<strong>枚举</strong>所有可能的分解策略。子问题的重复计算可以通过“programming”避免。</p><h1 id="Matrix-Chain-Multiplication-problem-矩阵的链式乘法"><a href="#Matrix-Chain-Multiplication-problem-矩阵的链式乘法" class="headerlink" title="Matrix Chain Multiplication problem 矩阵的链式乘法"></a>Matrix Chain Multiplication problem 矩阵的链式乘法</h1><hr><p>INPUT:A sequence of n matrices $A_1, A_2 , …, A_n$; matrix A i has dimension $p_{i-1} \times p_i$</p><p>OUTPUT:Fully parenthesizing the product $A_1, A_2 , …, A_n$ in a way to minimize the number of scalar multiplications.</p><hr><script type="math/tex; mode=display">A_1 = \left[\begin{matrix} 1 & 2 \end{matrix}\right] A_2 = \left[ \begin{matrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{matrix} \right] A_3 =\left[\begin{matrix} 1 & 2 & 3 & 4\\ 4 & 5 & 6 & 7\\7 & 8 & 9 & 10\end{matrix} \right]</script><p>Solutions: </p><p>$((A_1)(A_2))(A_3) : (1 \times 2 \times 3) + (1 \times 3 \times 4)$ </p><p>$(A_1)((A_2)(A_3)) : (2 \times 3 \times 4) + (1 \times 2 \times 4)$</p><p>我们要如何选取矩阵相乘的顺序来使乘的次数最小呢？</p><p>若枚举所有可能的解法，时间复杂度是指数级的。我们可以将其想象成一个多步决策，将加括号看成子问题。我们使用OPT(i,j)来表示子问题，原问题可以通过计算OPT(1,n)解决。由于<strong>最优子结构</strong>性质，我们可以通过计算子问题的最优解计算出原问题的最优解。</p><script type="math/tex; mode=display">OPT(1,n) = OPT(1,k) + OPT(k+1,n) + p_1p_{k+1}p_{n+1}</script><p>我们可以通过<strong>枚举</strong>所有可能的解来获得第一步决策。</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fwesfnsyvnj20e405a0t4.jpg" alt="recursive slt"></p><h2 id="Trials"><a href="#Trials" class="headerlink" title="Trials"></a>Trials</h2><h3 id="Trial-1"><a href="#Trial-1" class="headerlink" title="Trial 1"></a>Trial 1</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">RECURSIVE MATRIX CHAIN(i, j)</span><br><span class="line">    if i &#x3D;&#x3D; j then </span><br><span class="line">        return 0; </span><br><span class="line">    end if </span><br><span class="line">    OPT(i, j) &#x3D; +∞; </span><br><span class="line">    for k &#x3D; i to j − 1 do </span><br><span class="line">        q &#x3D; RECURSIVE MATRIX CHAIN(i, k) </span><br><span class="line">            + RECURSIVE MATRIX CHAIN(k + 1, j) + p_(i−1) p_k p_j ; </span><br><span class="line">        if q &lt; OPT(i, j) then </span><br><span class="line">            OPT(i, j) &#x3D; q; </span><br><span class="line">        end if </span><br><span class="line">    end for </span><br><span class="line">    return OPT(i, j);</span><br></pre></td></tr></table></figure><p>最优解：RECURSIVE MATRIX CHAIN(1, n)</p><p>然而，这种方式需要花费指数时间$O(n^2)$，且有大量的重复计算。我们可以开一个二维数组来存储subsolution，之后查表即可。</p><h3 id="Trial-2"><a href="#Trial-2" class="headerlink" title="Trial 2"></a>Trial 2</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">MEMORIZE_MATRIX_CHAIN(i, j) </span><br><span class="line">    if OPT[i, j] !&#x3D; NULL then </span><br><span class="line">        return OPT(i, j); </span><br><span class="line">    end if </span><br><span class="line">    if i &#x3D;&#x3D; j then </span><br><span class="line">        OPT[i, j] &#x3D; 0; </span><br><span class="line">        else </span><br><span class="line">        for k &#x3D; i to j − 1 do </span><br><span class="line">            q &#x3D; MEMORIZE MATRIX CHAIN(i, k) </span><br><span class="line">                +MEMORIZE MATRIX CHAIN(k + 1, j) </span><br><span class="line">                    +p i−1 p k p j ; </span><br><span class="line">            if q &lt; OPT[i, j] then </span><br><span class="line">                OPT[i, j] &#x3D; q; </span><br><span class="line">            end if </span><br><span class="line">        end for </span><br><span class="line">    end if </span><br><span class="line">    return OPT[i, j];</span><br></pre></td></tr></table></figure><p>原问题可以通过调用MEMORIZE_MATRIX_CHAIN(1, n)并 将所有OPT[i,j]设为NULL来解决。时间复杂度为$O(n^3)$</p><h3 id="Trial-3"><a href="#Trial-3" class="headerlink" title="Trial 3"></a>Trial 3</h3><p>更快的一种解决方式：自底向上迭代<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">MATRIX CHAIN MULTIPLICATION(p 0 , p 1 , ..., p n )</span><br><span class="line">    for i &#x3D; 1 to n do </span><br><span class="line">        OPT(i, i) &#x3D; 0; </span><br><span class="line">    end for </span><br><span class="line">    for l &#x3D; 2 to n do </span><br><span class="line">        for i &#x3D; 1 to n − l + 1 do </span><br><span class="line">            j &#x3D; i + l − 1; </span><br><span class="line">            OPT(i, j) &#x3D; +∞; </span><br><span class="line">            for k &#x3D; i to j − 1 do</span><br><span class="line">                q &#x3D; OPT(i, k) + OPT(k + 1, j) + p i−1 p k p j ; </span><br><span class="line">                if q &lt; OPT(i, j) then </span><br><span class="line">                    OPT(i, j) &#x3D; q; </span><br><span class="line">                    S(i, j) &#x3D; k; </span><br><span class="line">                end if </span><br><span class="line">            end for </span><br><span class="line">        end for </span><br><span class="line">    end for </span><br><span class="line">    return OPT(1, n);</span><br></pre></td></tr></table></figure><br><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fwesfntaifj20nb089dgw.jpg" alt=""></p><p>解题顺序：红 $\Rightarrow$ 绿 $\Rightarrow$ 橙 $\Rightarrow$ 蓝，自底而上，先列出所有子问题</p><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fwesfnswo9j20f207rdge.jpg" alt=""></p><p><strong>step 1：</strong></p><p>OPT[1,2],OPT[2,3],OPT[3,4]</p><p><strong>step 2：</strong></p><script type="math/tex; mode=display">OPT[1,3] = min \left\{ \begin{aligned} OPT[1,2] + OPT[3,3] + p_0 \times p_2 \times p_3 \\ OPT[1,1] + OPT[2,3] + p_0 \times p_1 \times p_3  \end{aligned} \right.</script><p>Thus, SPLITTER[1,2] = 2.</p><script type="math/tex; mode=display">OPT[1,3] = min \left\{ \begin{aligned} OPT[2,2] + OPT[3,4] + p_1 \times p_2 \times p_4 \\ OPT[2,3] + OPT[4,4] + p_1 \times p_3 \times p_4  \end{aligned} \right.</script><p>Thus, SPLITTER[2,4] = 3.</p><p><strong>step 3：</strong></p><script type="math/tex; mode=display">OPT[1,3] = min \left\{ \begin{aligned} OPT[1,1] + OPT[2,4] + p_0 \times p_1 \times p_4 \\ OPT[1,2] + OPT[3,4] + p_0 \times p_2 \times p_4 \\ OPT[1,3] + OPT[4,4] + p_0 \times p_3 \times p_4  \end{aligned} \right.</script><p>Thus, SPLITTER[1,4] = 3.</p><p>在此方法中，只有子问题的最优解被计算，因此没有经过遍历，不是指数级的复杂度。</p><h2 id="Backtracking"><a href="#Backtracking" class="headerlink" title="Backtracking"></a>Backtracking</h2><p>从OPT[1,n]开始回溯每一个决策阶段。</p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fwesfnst9hj20eo07fmxk.jpg" alt=""></p><p>Step 1: $(A_1A_2A_3)(A_4)$</p><p>Step 2: $((A_1A_2)(A_3))(A_4)$</p><p>Step 3: $(((A_1)(A_2)(A_3))(A_4)$</p><h1 id="0-1-KNAPSACK-problem-0-1背包问题"><a href="#0-1-KNAPSACK-problem-0-1背包问题" class="headerlink" title="0/1 KNAPSACK problem 0/1背包问题"></a>0/1 KNAPSACK problem 0/1背包问题</h1><hr><p>INPUT: A set of items $S = \{1, 2, …, n\}$. Item i has weight $w_i$ and value $v_i$ . A total weight limit W;<br>OUTPUT: A subset of items to maximize the total value with total weight below W.</p><hr><p>这里的0和1表示我们可以选择一个物品(1)或者放弃它(0)，我们不能选择物品的一部分。</p><p>我们可以将将最优解表示为：$OPT({1,2,…,i},w)$</p><p>最优子结构：</p><script type="math/tex; mode=display">OPT({1,2,...,n},W) = max \left\{\begin{array}{lr}OPT({1,2,...,n-1},W) \\OPT({1,2,...,n-1},W-w_n) + v_n\end{array}\right.</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Knapsack(n, W)</span><br><span class="line">    for w &#x3D; 1 to W do </span><br><span class="line">        OPT[0, w] &#x3D; 0; </span><br><span class="line">    end for </span><br><span class="line">    for i &#x3D; 1 to n do </span><br><span class="line">        for w &#x3D; 1 to W do </span><br><span class="line">            OPT[i, w] &#x3D; max&#123;OPT[i−1, w], vi +OPT[i−1, w−wi]&#125;; </span><br><span class="line">        end for </span><br><span class="line">    end for</span><br></pre></td></tr></table></figure><p>我们使用OPT[I,w]来表示OPT({1,2,…,i},w).</p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fwesfnsy67j20bq05h74v.jpg" alt=""></p><p><strong>step 1：</strong></p><p>Initially all OPT[0, w] = 0.</p><p><strong>step 2：</strong></p><script type="math/tex; mode=display">OPT[1, 2] = max\{ OPT[0, 2], OPT[0, 0] + V_1 \} =2</script><p><strong>step 3：</strong></p><script type="math/tex; mode=display">OPT[2, 4] = max\{ OPT[1, 4], OPT[1, 2] + V_2\} =4</script><p><strong>step 4：</strong></p><script type="math/tex; mode=display">OPT[3, 3] = max\{OPT[2, 3], OPT[2, 0] + V_3\} =3</script><p><strong>backtracking</strong></p><script type="math/tex; mode=display">OPT[3, 6] = max{ OPT[2, 6](= 4), OPT[2, 3] + V_3 (= 2 + 3)} =5</script><p>Decision: Select item 3</p><script type="math/tex; mode=display">OPT[2, 3] = max{ OPT[1, 3](= 2), OPT[1, 1] + V_2 (= 0 + 2)} =2</script><p>Decision: Select item 2</p><p>时间复杂度：$O(nW)$</p><p>若将items看做是集合（recursion over sets），将花费指数倍的时间；但是若将items先进行排序（recursion over sequences），花费的时间为$O(nW)$。</p><h1 id="Sequence-Alignment-problem"><a href="#Sequence-Alignment-problem" class="headerlink" title="Sequence Alignment problem"></a>Sequence Alignment problem</h1><p><strong>Alignment</strong> is introduced to describe the generating process of an erroneous word from the correct word using a series of INS/DEL/MUTATION operations.</p><p>要比较两个序列，我们首先在合适的地方引入空格-。使得两个序列的长度相同，即$|S’ = T’|$</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fwesfnrx4nj206s02rglr.jpg" alt=""></p><p>对齐的字符可能有三种情况：</p><ol><li>S’[i] = “-“ : S’[i] is simply a DELETION of T’[i].</li><li>T’[i] = “-“ : S’[i] is simply an INSERTION.</li><li>Otherwise, S’[i] is a copy of T’[i] (with possible MUTATION).</li></ol><p>我们可以用以下方式来给s(a,b)打分：</p><ol><li>Match: +1 , e.g. s(‘C’ ,’C’ ) = 1.</li><li>Mismatch: -1, e.g. s(‘E’ , ‘A’ ) = −1.</li><li>Insertion/Deletion: -3, e.g. s(‘C’ , ‘-‘ ) = −3.</li></ol><p>使用对齐，我们可以找到最相似的来源，并且同样两个序列，通过不同的插入空格的方式我们可以得到不同的值。</p><hr><p>INPUT:Two sequences S and T, |S| = m, and |T| = n;<br>OUTPUT:To identify an alignment of S and T that maximizes a pre-deﬁned scoring function.</p><hr><p>这里也有三种需要考虑的情况：</p><ol><li>$S_m$ comes from $T_n$:S从T产生</li><li>$S_m$ is an INSERTION：若S的最后一个字母多敲了</li><li>$S_m$ comes from T[1..n − 1]：若S少敲了</li></ol><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fwesfnutixj20lg05hdgb.jpg" alt=""></p><p>note:蓝色框表示子问题</p><p>因此，我们可以将子问题的一般式设计为S的前缀(S[1..i])和T的的前缀(T[1..j])。最优解可以被表示为OPT(i,j).</p><script type="math/tex; mode=display">OPT(i,j) = max \left\{\begin{array}{lr}s(S_i,T_j) + OPT(i-1, j-1) \\s('-',T_j) + OPT(i, j-1) \\s(S_i,'-') + OPT(i-1, j)\end{array}\right.</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Needleman-Wunsch(S, T)</span><br><span class="line">    for i &#x3D; 0 to m; do   \\简单的初始化，为了方便计算</span><br><span class="line">        OPT[i, 0] &#x3D; −3 ∗ i; </span><br><span class="line">    end for </span><br><span class="line">    for j &#x3D; 0 to n; do </span><br><span class="line">        OPT[0, j] &#x3D; −3 ∗ j; </span><br><span class="line">    end for </span><br><span class="line">    for i &#x3D; 1 to m do </span><br><span class="line">        for j &#x3D; 1 to n do </span><br><span class="line">            \\从三个单元里各自取了一些分，取最大</span><br><span class="line">            OPT[i,j]&#x3D;max&#123;OPT[i−1,j−1]+s(Si,Tj),OPT[i-1,j]−3,OPT[i,j−1]−3&#125;;  </span><br><span class="line">        end for </span><br><span class="line">    end for </span><br><span class="line">    return OPT[m, n] ;</span><br></pre></td></tr></table></figure><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fwesfnwzbzj20dt0dgabl.jpg" alt=""></p><p>之后通过<strong>回溯</strong>找到最优对齐方式（开一个表格方便回溯）：</p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fwesfnxbxaj20dm0dlgng.jpg" alt=""></p><p>在实践中，有许多中对齐方式可以达到与最优比对相似的效果，被称作次优比对。次优比对可以分为两类：1)类似的次优比对，2)不同的次优比对。</p><p>为了找到类似的次优对齐，我们使用采样技术追溯动态编程矩阵，即，不是在每个步骤采用最高得分选项，而是基于三个选项的值进行概率选择。e.g.将4以一定的概率回到之前的三个点，找一百回，用聚类的算法找到聚类中心。（最robust）</p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>若输入的数据很大（e.g.输入了两篇文章）这个算法面临了三个问题：</p><ol><li>占用空间太大</li><li>用时太长</li><li>Local</li></ol><h3 id="Space-eﬃcient-algorithm"><a href="#Space-eﬃcient-algorithm" class="headerlink" title="Space eﬃcient algorithm:"></a>Space eﬃcient algorithm:</h3><p>Reducing the space requirement from O(mn) to O(m + n) (D. S. Hirschberg, 1975).</p><p>若只计算分数而不记录对齐信息，占用的空间很小。因为我们仅需占用2个数组。绿色数组：已填，蓝色数组：待填，一旦把蓝色的数组填完，绿色的数组就没用了。白色的部分都不需要存。</p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fwesg4xtq3j20d50data5.jpg" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Prefix Space Efficient Alignment(S, T, score)</span><br><span class="line">    for i &#x3D; 0 to m do </span><br><span class="line">        score[i] &#x3D; −3 ∗ i;   \\绿色数组</span><br><span class="line">    end for </span><br><span class="line">    for i &#x3D; 1 to m do </span><br><span class="line">        newscore[0] &#x3D; 0;      \\蓝色数组</span><br><span class="line">        for j &#x3D; 1 to n do </span><br><span class="line">            newscore[j] &#x3D; max&#123;score[j − 1] + s(S i , T j ), score[j] 3, newscore[j − 1] − 3&#125;; </span><br><span class="line">        end for </span><br><span class="line">        for j &#x3D; 1 to n do </span><br><span class="line">            score[j] &#x3D; newscore[j]; </span><br><span class="line">        end for </span><br><span class="line">    end for </span><br><span class="line">    return score[n];</span><br></pre></td></tr></table></figure><p>相应地，我们也可以使用S和T的后缀获得分数和对齐方式。</p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fwesg4mo4ej20dc0dkjsx.jpg" alt=""></p><p>但是这种方式无法回溯对齐信息。因此，一种更聪明的方式是我们可以将S分为两半(where $S_{\frac{m}{2}}$is aligned to,denoted as q)，分别计算对齐信息。</p><script type="math/tex; mode=display">OPT(S,T) = OPT(S[1...\frac{m}{2}],T[1..q])+OPT(S[\frac{m}{2}+1..m],T[q+1..n])</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Linear Space Alignment( S, T )</span><br><span class="line">    Allocate two arrays f and b; each array has a size of m Prefix Space Efficient Alignment(S[1.. m ], T, f); </span><br><span class="line">    Suffix Space Efficient Alignment(S[ m + 1..m], T, b); </span><br><span class="line">    Let q &#x3D; argmaxi (f[i] + b[i]); </span><br><span class="line">    Free arrays f and b; </span><br><span class="line">    Record aligned-position &lt; m&#x2F;2 , q &gt; in an array A; </span><br><span class="line">    Linear Space Alignment(S[1.. m ], T[1..q]); </span><br><span class="line">    Linear Space Alignment(S[ m + 1..m], T[q + 1..n]); </span><br><span class="line">    return A;</span><br></pre></td></tr></table></figure><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fwesg4o38wj20jp0f1mz5.jpg" alt=""><br><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fwesg4nrcej20jq0f5gnj.jpg" alt=""></p><p>先把S分为恰好左一半（前缀，forward）和右一半（后缀，backward），拿’OCUR’与T的总体作比较.从图中可以看出，分数一定是由S前一半的上半部分和后一半的下半部分产生。</p><p>由此，所需的空间仅为$O(m+n)$.</p><h3 id="Time-complexity"><a href="#Time-complexity" class="headerlink" title="Time complexity"></a>Time complexity</h3><p>我们可以发现，足够相似的是对角线，因此我们可以只关心条带内。<br>Banded DP仅需花费$O(\alpha n)$的时间复杂度。它为线性的算法，比原来快得多，条带外的部分我们可以不用考虑。</p><h3 id="Local"><a href="#Local" class="headerlink" title="Local"></a>Local</h3><p>全局比对：识别两个完整序列之间的相似性。</p><p>局部对齐：我们通常希望找到相似的段（子序列）。<br>局部对齐的目的是识别两个序列的相似区段。 其他区域可以被视为独立的，因此形成“随机匹配”。</p><p>通过增加额外的概率来改变递归：</p><script type="math/tex; mode=display">OPT(i,j) = max \left\{\begin{array}{lr}0 \\s(S_i,T_j) + OPT(i-1, j-1) \\s('-',T_j) + OPT(i, j-1) \\s(S_i,'-') + OPT(i-1, j)\end{array}\right.</script><p>其中0对应一个新的对齐。它与旧的对齐无关。</p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fwesg4n05xj20aa0b9q4v.jpg" alt=""></p><p>与从右下角回溯不同，这里从最大的项开始回溯，13为相似的终点，右下角的7为相似+不同。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Main message:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;把子问题的求解想象成多步求解过程&lt;/li&gt;
&lt;li&gt;子问题的最优解可以组合成原问题的最优解&lt;/li&gt;
&lt;li&gt;Programming：tabular可以被用于避免子问题的重复计算&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="algorithm" scheme="http://yoursite.com/categories/algorithm/"/>
    
    
      <category term="Algorithm Design and Analysis" scheme="http://yoursite.com/tags/Algorithm-Design-and-Analysis/"/>
    
      <category term="Basic algorithm design technique" scheme="http://yoursite.com/tags/Basic-algorithm-design-technique/"/>
    
      <category term="Dynamic programming" scheme="http://yoursite.com/tags/Dynamic-programming/"/>
    
      <category term="Optimization" scheme="http://yoursite.com/tags/Optimization/"/>
    
  </entry>
  
  <entry>
    <title>Algorithm Design and Analysis - Divide-and-Conquer</title>
    <link href="http://yoursite.com/2018/09/24/Algorithm-Design-and-Analysis-Divide-and-Conquer/"/>
    <id>http://yoursite.com/2018/09/24/Algorithm-Design-and-Analysis-Divide-and-Conquer/</id>
    <published>2018-09-24T06:44:42.000Z</published>
    <updated>2019-03-22T12:16:22.326Z</updated>
    
    <content type="html"><![CDATA[<p>Main message:</p><ol><li>从最简单的case入手</li><li>看能否分，能否combine</li><li>不求最优，只要次优</li></ol><a id="more"></a><h1 id="一、Remarks"><a href="#一、Remarks" class="headerlink" title="一、Remarks"></a>一、Remarks</h1><p>1.对于ClosestPair问题，若暴力破解法将花费多项式时间，分治法通常可被用于节省运行时间：$O(n^2)$ $\implies$ $O(nlogn)$<br>2.这个技巧若与随机技巧结合将非常有威力</p><p>在使用分治法之前，需要先检验输入（i.e.问题是否可以被分为结构相似，规模更小的子问题）以及输出（i.e.原问题的解是否能够用子问题的解组合而成）</p><h1 id="二、Sort-Problem"><a href="#二、Sort-Problem" class="headerlink" title="二、Sort Problem"></a>二、Sort Problem</h1><p>将长度为n的数组排序</p><pre><code>INPUT: An array of n integers, say A[0..n-1];OUTPUT: The items of A in increasing order.</code></pre><p><strong><em>方法1.将其分为n-1长度的数列和一个元素</em></strong></p><p>第一种方法可以从最简单的case入手，从n=2，n=3，到逐步解决原问题</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fvl1co5hjuj20cw0atgmq.jpg" alt="分离出一个元素"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">InsertionSort( A, n )</span><br><span class="line">for j &#x3D; 0 to n - 1 do</span><br><span class="line">key &#x3D; A[j];</span><br><span class="line">i &#x3D; j - 1;</span><br><span class="line">while i &gt;&#x3D; 0 and A[i] &gt; key do</span><br><span class="line">A[i + 1] &#x3D; A[i];</span><br><span class="line">i --;</span><br><span class="line">end while</span><br><span class="line">A[i + 1] &#x3D; key;</span><br><span class="line">end for</span><br></pre></td></tr></table></figure><p>最差的情况：A数组里的元素为逆序</p><p>时间复杂度： $T(n)=T(n-1)+O(n)=O(n^2)$</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fvl1cnv0q4j206e0a3ab1.jpg" alt="最差情况"></p><p><strong><em>方法2.将其分为两个独立的子问题(MERGE SORT)</em></strong></p><p>将数组$A[0..n-1]$分为两个数组$A[0..\frac{n}{2}-1]$以及$A[\frac{n}{2}-1..n-1]$</p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fvl1cnxlrkj20f30armzr.jpg" alt="分为子问题"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">MergeSort(A; l; r) &#x2F;&#x2F;从l到r之间排序</span><br><span class="line">&#x2F;&#x2F; To sort part of the array A[l::r]</span><br><span class="line">if l &lt; r then</span><br><span class="line">m &#x3D; (l + r)&#x3D;2; &#x2F;&#x2F;m denotes the middle point</span><br><span class="line">MergeSort(A; l; m );</span><br><span class="line">MergeSort(A; m + 1; r);</span><br><span class="line">Merge(A; l; m; r); &#x2F;&#x2F;Combining the sorted arrays</span><br><span class="line">end if</span><br><span class="line">Merge (A; l; m; r) &#x2F;&#x2F;将左端最小与右端最小比较</span><br><span class="line">&#x2F;&#x2F;Merge A[l::m] (denoted as L) and A[m + 1::r](denoted as R).</span><br><span class="line">i &#x3D; 0; j &#x3D; 0;</span><br><span class="line">for k &#x3D; l to r do</span><br><span class="line">if L[i] &lt; R[j] then</span><br><span class="line">A[k] &#x3D; L[i];</span><br><span class="line">i + +;</span><br><span class="line">else</span><br><span class="line">A[k] &#x3D; R[j];</span><br><span class="line">j + +;</span><br><span class="line">end if</span><br><span class="line">end for</span><br></pre></td></tr></table></figure><p>时间复杂度：O(n)</p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fvl1cnuxq5j20ea02v74x.jpg" alt="mergesort"></p><h1 id="三、迭代的时间复杂度的分析方法："><a href="#三、迭代的时间复杂度的分析方法：" class="headerlink" title="三、迭代的时间复杂度的分析方法："></a>三、迭代的时间复杂度的分析方法：</h1><ol><li>Unrolling the recurrence 硬展开</li><li>Guess and substitution 猜然后验证</li><li>Master theorem</li></ol><h3 id="technique-1-Unrolling-the-recurrence"><a href="#technique-1-Unrolling-the-recurrence" class="headerlink" title="technique 1: Unrolling the recurrence"></a>technique 1: Unrolling the recurrence</h3><p>We have $T(n) = 2T(\frac{n}{2}) + O(n) &lt;= 2T(\frac{n}{2}) + cn$ for a constant c. Let unrolling a few levels to find a pattern, and then sum over all levels.</p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fvl1cnvn1mj20c408dt9u.jpg" alt="Unrolling"></p><h3 id="technique-2-Guess-and-substitution"><a href="#technique-2-Guess-and-substitution" class="headerlink" title="technique 2: Guess and substitution"></a>technique 2: Guess and substitution</h3><p>Guess and substitution: guess a solution, substitute it into the recurrence relation, and justify that it works.</p><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fvl1cnxy0gj20gv08kq4g.jpg" alt="Guess"></p><h3 id="technique-3-Master-theorem-主定理"><a href="#technique-3-Master-theorem-主定理" class="headerlink" title="technique 3:Master theorem  主定理"></a>technique 3:Master theorem  主定理</h3><p>Let T(n) be defined by $T(n)=aT(\frac{n}{b})+O(n^d)$ for a &gt; 1, b &gt; 1 and d &gt; 0, 其中n为问题规模，a为递推的子问题数量,$\frac{n}{b}$为每个子问题的规模（假设每个子问题的规模基本一样），  为递推以外进行的计算工作.<br>then T(n) can be bounded by:</p><ol><li>If d &lt; $\log_b a$, then $T(n)=O(n^{\log_b a})$;</li><li>If d = $\log_b a$, then $T(n)=O(n^{\log_b a} \log n)$;</li><li>If d &gt; $\log_b a$, then $T(n)=O(n^d)$.</li></ol><h1 id="四、Counting-Inversion-Problem-数逆序对"><a href="#四、Counting-Inversion-Problem-数逆序对" class="headerlink" title="四、Counting Inversion Problem  数逆序对"></a>四、Counting Inversion Problem  数逆序对</h1><p>To count inversions in an array of n integers</p><pre><code>INPUT: An array $A[0..n]$ with n distinct numbers; OUTPUT:the number of inversions. A pair of indices i and j constitutes an inversion if i &lt; j butA[i] &gt; A[j].</code></pre><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fvl1cnupelj20ak041aa8.jpg" alt="CountingInversion"></p><p>可使用分治法解决数逆序对问题，其中Divide和Conquer部分与之前排序问题相同，即将问题分为两个独立的子问题。Combine部分有两种策略。</p><p><strong>策略1</strong>：若$A[0..\frac{n}{2}-1]$以及$A[\frac{n}{2}..n-1]$没有特殊的结构，则我们需要检查所有可能的配对$(i,j)$去检查逆序。即若左右数都是任意的，就必须写For循环。</p><p>时间复杂度为：$T(n)=2T(\frac{n}{2})+\frac{n^2}{4}=O(n^2)$</p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fvl1cnyqh7j20d007h0uj.jpg" alt="strategy1"></p><p><strong>策略2</strong>：若每一部分为升序，则相对容易计算逆序</p><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fvl1co2bztj20cv06bjsg.jpg" alt="strategy2"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Sort-and-Count(A)</span><br><span class="line">Divide A into two sub-sequences L and R;</span><br><span class="line">(RCL, L) &#x3D; Sort-and-Count(L);</span><br><span class="line">(RCR, R) &#x3D; Sort-and-Count(R);</span><br><span class="line">(C, A) &#x3D; Merge-and-Count(L, R);</span><br><span class="line">return (RC &#x3D; RCL + RCR + C, A);</span><br><span class="line">Merge-and-Count (L; R)</span><br><span class="line">RC &#x3D; 0; i &#x3D; 0; j &#x3D; 0;</span><br><span class="line">for k &#x3D; 0 to ∥L∥ + ∥R∥ - 1 do</span><br><span class="line">if L[i] &gt; R[j] then</span><br><span class="line">A[k] &#x3D; R[j];</span><br><span class="line">j + +;</span><br><span class="line">RC+ &#x3D; (n&#x2F;2 - i);</span><br><span class="line">else</span><br><span class="line">A[k] &#x3D; L[i];</span><br><span class="line">i + +;</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">return (RC, A);</span><br></pre></td></tr></table></figure><p>时间复杂度为：$T(n)=2T(\frac{n}{2})+O(n)=O(n\log n)$</p><h1 id="五、The-general-Divide-and-Conquer-paradigm"><a href="#五、The-general-Divide-and-Conquer-paradigm" class="headerlink" title="五、The general Divide and Conquer paradigm"></a>五、The general Divide and Conquer paradigm</h1><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>Many problems are recursive in structure, i.e., to solve a given problem, they call themselves several times to deal with closely related sub-problems. These sub-problems have the same form to the original problem but a smaller size.</p><h2 id="Three-Steps"><a href="#Three-Steps" class="headerlink" title="Three Steps"></a>Three Steps</h2><ol><li><strong><em>Divide</em></strong> a problem into a number of independent <strong><em>sub-problems</em></strong>;</li><li><strong><em>Conquer</em></strong> the subproblems by solving them recursively;</li><li><strong><em>Combine</em></strong> the solutions to the subproblems into the solution to the original problem.</li></ol><h2 id="Quick-Sort-algorithm"><a href="#Quick-Sort-algorithm" class="headerlink" title="Quick Sort algorithm"></a>Quick Sort algorithm</h2><p>Divide according to a randomly-selected pivot.根据随机选取的轴进行分割。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">QuickSort(A)</span><br><span class="line">S_ &#x3D; &#123;&#125;; S+ &#x3D; &#123;&#125;;</span><br><span class="line">Choose a pivot A[j] uniformly at random;</span><br><span class="line">for i &#x3D; 0 to n - 1 do  &#x2F;&#x2F;将比A[j]小的放在左边，大的放在右边</span><br><span class="line">Put A[i] in S_ if A[i] &lt; A[j];</span><br><span class="line">Put A[i] in S+ if A[i] &gt;&#x3D; A[j];</span><br><span class="line">end for</span><br><span class="line">QuickSort(S+);</span><br><span class="line">QuickSort(S_);</span><br><span class="line">Output S_, then A[j], then S+;</span><br></pre></td></tr></table></figure><ul><li>随机的操作使得这个算法变得简单而高效</li><li>然而，随机增加了分析的难度，我们不能保证取到每个问题的第$\frac{n}{2}$个元素</li></ul><p><strong>最差的情况</strong>：选取到了每个迭代中最大/最小的元素</p><script type="math/tex; mode=display">T(n) = T(n - 1) + O(n) = O(n^2)</script><p><strong>最好的情况</strong>：选取到了每个迭代中最中间的元素</p><script type="math/tex; mode=display">T(n) = 2T(\frac{n}{2}) + O(n) = O(n\log n)</script><p><strong>大多数情况</strong>：选取到了一个接近中心的轴。这种情况我们认为期望的运行时间仍为：</p><script type="math/tex; mode=display">T(n) = O(n\log n)</script><h2 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h2><p><strong>Observation 1:</strong> 对于任意i,j而言，$A[i]$和$A[j]$之间最多被比较一次。</p><p><strong>Observation 2:</strong> 当处理包含$A[i..j]$的元素时，当且仅当$A[i]$或$A[j]$被选为枢轴时比较$A[i]$和$A[j]$。</p><h2 id="Modified-Quick-Sort"><a href="#Modified-Quick-Sort" class="headerlink" title="Modified Quick Sort"></a>Modified Quick Sort</h2><p>在原算法上寻找一个好的分点（大于$/frac{n}{4}$小于$/frac{3n}{4}$的点）。它在所有项目都不同时有用，然而耗内存，且在比原算法更慢，因为当它偏离中心点时不运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">ModifiedQuickSort(A)</span><br><span class="line">while TRUE do</span><br><span class="line">Choose a pivot A[j] uniformly at random;</span><br><span class="line">S_ &#x3D; &#123;&#125;; S+ &#x3D; &#123;&#125;;</span><br><span class="line">for i &#x3D; 0 to n - 1 do</span><br><span class="line">Put A[i] in S_ if A[i] &lt; A[j];</span><br><span class="line">Put A[i] in S+ if A[i] &gt; A[j];</span><br><span class="line">end for</span><br><span class="line">if ∥S+∥ &gt;&#x3D; n&#x2F;4 and ∥S_∥ &gt;&#x3D; n&#x2F;4 then</span><br><span class="line">break;</span><br><span class="line">end if</span><br><span class="line">end while</span><br><span class="line">ModifiedQuickSort(S+);</span><br><span class="line">ModifiedQuickSort(S_);</span><br><span class="line">Output S_, then A[j], and finally S+;</span><br></pre></td></tr></table></figure><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fvnb5mr9sfj20bt04ojrv.jpg" alt="nearcenter"></p><p>比起中心轴，近中心轴更容易获得。获得一个中心点为轴的概率是$frac{1}{n}$,而获得一个近中心轴的概率是$frac{1}{2}$。因此，找到一个近中心轴的期望时间为2n。此时我们不追求最优的pivot，只选择足够好。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">\\Lomuto’s implementation</span><br><span class="line">\\in-place sort 不花内存。</span><br><span class="line">QuickSort(A; l; h)</span><br><span class="line">if l &lt; h then</span><br><span class="line">p &#x3D;Partition(A; l; h);</span><br><span class="line">QuickSort(A; l; p - 1);</span><br><span class="line">QuickSort(A; p + 1; h);</span><br><span class="line">end if</span><br><span class="line">Partition(A; l; h)</span><br><span class="line">pivot &#x3D; A[h]; i &#x3D; l - 1;</span><br><span class="line">for j &#x3D; l to h - 1 do</span><br><span class="line">if A[j] &lt; pivot then</span><br><span class="line">i + +;</span><br><span class="line">Swap A[i] with A[j];</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">if A[h] &lt; A[i + 1] then</span><br><span class="line">Swap A[i + 1] with A[h];</span><br><span class="line">end if</span><br><span class="line">return i + 1;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">\\Hoare’s implementation</span><br><span class="line">QuickSort(A; l; h)</span><br><span class="line">if l &lt; h then</span><br><span class="line">p &#x3D;Partition(A; l; h);</span><br><span class="line">QuickSort(A; l; p); &#x2F;&#x2F;Reason: A[p] might not be at its correct position</span><br><span class="line">QuickSort(A; p + 1; h);</span><br><span class="line">end if</span><br><span class="line">Partition(A; l; h)</span><br><span class="line">i &#x3D; l - 1; j &#x3D; h + 1; pivot &#x3D; A[l];</span><br><span class="line">while TRUE do</span><br><span class="line">repeat</span><br><span class="line">j &#x3D; j - 1;</span><br><span class="line">until A[j] &lt;&#x3D; pivot or j &#x3D;&#x3D; l;</span><br><span class="line">repeat</span><br><span class="line">i &#x3D; i + 1;</span><br><span class="line">until A[i] &gt;&#x3D; pivot or i &#x3D;&#x3D; h;</span><br><span class="line">if i &gt;&#x3D; j then</span><br><span class="line">return j;</span><br><span class="line">end if</span><br><span class="line">Swap A[i] with A[j];</span><br><span class="line">end while</span><br></pre></td></tr></table></figure><blockquote><blockquote><p>快速排序只在无重复元素时性能好，若有重复的元素，可用PARTITION算法来解决这个问题，即将数列分为三部分：比pivot大，与pivot相等，比pivot小。仅需对不等于pivot的partitions进行迭代排序。</p></blockquote></blockquote><h2 id="Selection-problem"><a href="#Selection-problem" class="headerlink" title="Selection problem"></a>Selection problem</h2><p>找到数组中第K小的item</p><pre><code>INPUT:An array A = [A0, A1,.., An_1], and a number k &lt; n;OUTPUT:The k-th smallest item in general case (or the median of A as a specical case).</code></pre><p>若先将A排序再寻找第k个值，时间复杂度为$O(nlog n)$。相反地，若使用分治法，则有可能开发出更快的算法（e.g.deterministic linear algorithm by Blum et al.）。时间复杂度为$O(n)$。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Select(A; k)</span><br><span class="line">Choose an element Ai from A as a pivot;</span><br><span class="line">S+ &#x3D; &#123;&#125;;</span><br><span class="line">S_ &#x3D; &#123;&#125;;</span><br><span class="line">for j &#x3D; 1 to n do</span><br><span class="line">if Aj &gt; Ai then</span><br><span class="line">S+ &#x3D; S+ U &#123;Aj&#125;;</span><br><span class="line">else</span><br><span class="line">S_ &#x3D; S_ U &#123;Aj&#125;;</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">if |S_| &#x3D; k - 1 then</span><br><span class="line">return Ai;</span><br><span class="line">else if |S_| &gt; k - 1 then</span><br><span class="line">return Select(S_; k);  \\S的size越小越好</span><br><span class="line">else</span><br><span class="line">return Select(S+; k - |S_| + 1);</span><br><span class="line">end if</span><br></pre></td></tr></table></figure><h3 id="How-to-choose-a-pivot"><a href="#How-to-choose-a-pivot" class="headerlink" title="How to choose a pivot?"></a>How to choose a pivot?</h3><p>对于pivot（中心元），我们有三种选择方式：</p><p><strong>最差的选择</strong>：选取到了每个迭代中最小的元素(线性下降)</p><script type="math/tex; mode=display">T(n) = T(n - 1) + O(n) = O(n^2)</script><p><strong>最好的选择</strong>：选取到了每个迭代中最中间的元素（指数级下降）</p><script type="math/tex; mode=display">T(n) = T(\frac{n}{2}) + O(n) = O(n)</script><p><strong>好的选择</strong>：选取到了一个接近中心的pivot。（子问题最坏的情况也是指数级下降）</p><script type="math/tex; mode=display">T(n) ≤ T((1 − ϵ)n) + O(n) ≤ cn + c(1 − ϵ)n + c(1 − ϵ)^2 + ....=  O(n)</script><h3 id="How-to-select-a-nearly-central-pivot"><a href="#How-to-select-a-nearly-central-pivot" class="headerlink" title="How to select a nearly-central pivot?"></a>How to select a nearly-central pivot?</h3><p>我们可以通过以下几种方式尝试获得一个完整集合的中间值：</p><ul><li>Selecting a central pivot via <strong>examining medians of groups</strong></li><li>Selecting a central pivot via <strong>randomly selecting an element</strong></li><li>Selecting a central pivot via <strong>examining a random sample</strong></li></ul><h4 id="Strategy-1-BFPRT-algorithm-uses-median-of-medians-as-pivot"><a href="#Strategy-1-BFPRT-algorithm-uses-median-of-medians-as-pivot" class="headerlink" title="Strategy 1:BFPRT algorithm uses median of medians as pivot"></a>Strategy 1:BFPRT algorithm uses median of medians as pivot</h4><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fw46ro5745j20g803wgnc.jpg" alt="BFPRT"></p><p>SelectMedian(A)<br>    Line up elements in groups of 5 elements;</p><ol><li>Find the median of each group; //cost $\frac{6n}{5}$ time</li><li>Find the median of medians (denoted as M)through recursively running Select over the group medians; // $T(\frac{n}{5})$ time</li><li>Use M as pivot to partition A into S_ and S+; //$O(n)$ time</li><li>if |S_| = k - 1 then</li><li>return M;</li><li>else if |S_| &gt; k - 1 then</li><li>return Select(S_; k); //at most $T(\frac{7n}{10})$ time</li><li>else</li><li>return Select(S+; k - |S_| - 1); //at most $T(\frac{7n}{10})$ time</li><li>end if</li></ol><p>这种方法较耗内存，我们也可以使用原位替换的算法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">Select(A; l; r; k)</span><br><span class="line">while TRUE do</span><br><span class="line">if l &#x3D;&#x3D; r then</span><br><span class="line">return l;</span><br><span class="line">end if</span><br><span class="line">p &#x3D;Pivot(A; l; r); &#x2F;&#x2F;Use median of medians A[p] as pivot ;</span><br><span class="line">pos &#x3D;Partition(A; l; r; p); &#x2F;&#x2F;pos represents the final position of the pivot, A[l..pos - 1] deposit S_ and A[pos + 1..r] deposit S+;</span><br><span class="line">if (k - 1) &#x3D;&#x3D; pos then</span><br><span class="line">return k - 1;</span><br><span class="line">else if (k - 1) &lt; pos then</span><br><span class="line">r &#x3D; pos - 1;</span><br><span class="line">else</span><br><span class="line">l &#x3D; pos + 1;</span><br><span class="line">end if</span><br><span class="line">end while</span><br><span class="line">&#x2F;&#x2F;</span><br><span class="line">Pivot(A, l, r)</span><br><span class="line">if (r - l) &lt; 5 then</span><br><span class="line">return Partition5(A, l, r); &#x2F;&#x2F;Get median for 5 or less elements;</span><br><span class="line">end if</span><br><span class="line">for i &#x3D; l to r by 5 do</span><br><span class="line">right &#x3D; i + 4;</span><br><span class="line">if right &gt; r then</span><br><span class="line">right &#x3D; r;</span><br><span class="line">end if</span><br><span class="line">m &#x3D;Partition5(A, i, right); &#x2F;&#x2F;Get median of a group;</span><br><span class="line">Swap A[m] and A[l + [(i-1)&#x2F;5]];</span><br><span class="line">end for</span><br><span class="line">return Select(A, l, l + [(r-l)&#x2F;5],(r-l)&#x2F;10 + 1);</span><br><span class="line">&#x2F;&#x2F;</span><br><span class="line">Partition(A, l, r, p)</span><br><span class="line">pivot &#x3D; A[p];</span><br><span class="line">Swap A[p] and A[r]; &#x2F;&#x2F;Move pivot to the right end;</span><br><span class="line">i &#x3D; l;</span><br><span class="line">for j &#x3D; l to r - 1 do</span><br><span class="line">if A[j] &lt; pivot then</span><br><span class="line">Swap A[i] and A[j];</span><br><span class="line">i + +;</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">Swap A[r] and A[i];</span><br><span class="line">return i;</span><br></pre></td></tr></table></figure><p>图解：</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fw46ro5k3wj20i50cw422.jpg" alt="part1"></p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fw46ro5sauj20ga0czado.jpg" alt="part2"></p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fw46ro5n6bj20gr0dc42f.jpg" alt="part3"></p><h4 id="Strategy-2-QuickSelect-algorithm-randomly-select-an-element-as-pivot"><a href="#Strategy-2-QuickSelect-algorithm-randomly-select-an-element-as-pivot" class="headerlink" title="Strategy 2: QuickSelect algorithm randomly select an element as pivot"></a>Strategy 2: QuickSelect algorithm randomly select an element as pivot</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">QuickSelect(A, k)</span><br><span class="line">Choose an element Ai from A uniformly at random;</span><br><span class="line">S+ &#x3D; &#123;&#125;;</span><br><span class="line">S_ &#x3D; &#123;&#125;;</span><br><span class="line">for all element Aj in A do</span><br><span class="line">if Aj &gt; Ai then</span><br><span class="line">S+ &#x3D; S+ U &#123;Aj&#125;;</span><br><span class="line">else</span><br><span class="line">S_ &#x3D; S_ U &#123;Aj&#125;;</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">if |S_| &#x3D; k - 1 then</span><br><span class="line">return Ai;</span><br><span class="line">else if |S_| &gt; k - 1 then</span><br><span class="line">return QuickSelect(S_; k);</span><br><span class="line">else</span><br><span class="line">return QuickSelect(S+; k - |S_| - 1);</span><br><span class="line">end if</span><br></pre></td></tr></table></figure><p><strong>Basic idea:</strong> when selecting an element uniformly at random, it is highly likely to get a good pivot since a fairly large fraction of the elements are nearly-central.</p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fw46ro56shj20fi07wwg5.jpg" alt="atRandom"></p><p>The expected running time of QuickSelect: T(n) = O(n);</p><h4 id="Strategy-3-Floyd-Rivest-algorithm-selects-a-pivot-based-on-random-samples"><a href="#Strategy-3-Floyd-Rivest-algorithm-selects-a-pivot-based-on-random-samples" class="headerlink" title="Strategy 3: Floyd-Rivest algorithm selects a pivot based on random samples"></a>Strategy 3: Floyd-Rivest algorithm selects a pivot based on random samples</h4><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fw46t80bu9j208605l0sw.jpg" alt="Floyd-Rivest"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Floyd-Rivest-Select(A; k)</span><br><span class="line">Select a small random sample S (with replacement) from A.</span><br><span class="line">Select two pivots, denoted as u and v, from S through recursively calling Floyd-Rivest-Select. The interval [u, v], although small, is expected to cover the k-th smallest element of A.</span><br><span class="line">Divide A into three dis-joint subsets: L contains the elements less than u, M contains elements in [u; v], and H contains the elements greater than v.</span><br><span class="line">Partition A into these three sets through comparing each element Ai with u and v: if k &lt;&#x3D; n2, Ai is compared with v first and then to u only if Ai &lt;&#x3D; v. The order is reversed if k &gt; n2.</span><br><span class="line">The k-th smallest element of A is selected through recursively running over an appropriate subset.</span><br></pre></td></tr></table></figure><h1 id="六、例题"><a href="#六、例题" class="headerlink" title="六、例题"></a>六、例题</h1><p>note:一般来说，对于1维问题而言，我们可以将其分为两部分来解决问题。对于二维问题而言，我们可以将其分为横纵四个子问题来解决。但这并不是对所有情况都适用。</p><h2 id="1-ClosestPair-problem"><a href="#1-ClosestPair-problem" class="headerlink" title="1. ClosestPair problem"></a>1. ClosestPair problem</h2><p>Given a set of points in a plane, to find the closest pair.</p><pre><code>INPUT: n points in a plane;OUTPUT: The pair with the least Euclidean distance.</code></pre><p>暴力做法的时间复杂度为<script type="math/tex">T(n^2)</script>,存在很多的冗余。<br>由于将平面分为四个部分会使点的分布不均，我们将平面分割为内含均匀数量的点的两个平面，分别计算两个平面内的最小对点距离，再计算跨越两个平面的最小距离。<br>我们可以观察到，我们仅需检查中线周围以两个平面中较小的最小距离为宽度的区域就足够。</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fw46ro22y6j20df07vgm1.jpg" alt="ClosestPair1"></p><p>并且，我们不需要检查条形区域内的所有点。检查它周围的11个点已足够。<br>我们将两倍宽度的长条分解成格子，每个格子中最多包含一个点，否则表明之前计算出的最小距离有误。 我们对y轴进行排序，然后仅需将每个点与其周围11个点进行比对。</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fw46ro2bidj209b06qjrz.jpg" alt="ClosestPair2"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ClosestPair(pl; :::; pr)</span><br><span class="line">&#x2F;&#x2F;To find the closest points within (pl; :::; pr). Here we assume that pl,...,pr have already been sorted according to x-coordinate;</span><br><span class="line">if r - l &#x3D;&#x3D; 1 then</span><br><span class="line">return d(pl; pr);</span><br><span class="line">end if</span><br><span class="line">Use the x-coordinate of p((l+r)&#x2F;2) to divide pl,...,pr into two halves;</span><br><span class="line">d1 &#x3D; ClosestPair(LeftHalf); &#x2F;&#x2F;T(n2)</span><br><span class="line">d2 &#x3D; ClosestPair(RightHalf); &#x2F;&#x2F;T(n2)</span><br><span class="line">d &#x3D; min(d1; d2);</span><br><span class="line">Sort points within the 2d wide strip by y-coordinate; &#x2F;&#x2F;O(n log n)</span><br><span class="line">Scan points in y-order and calculate distance between each point with its next 11 neighbors. Update d if finding a distance less than d;  &#x2F;&#x2F;O(n)</span><br></pre></td></tr></table></figure><p>Time-complexity: <script type="math/tex">T(n) = 2T(\frac{n}{2}) + O(n log n) = O(n log^2 n)</script>.</p><p>为了是复杂度降到O(n),我们可以引入structure，使用merge将每一个子问题先排序。</p><p><strong>实例：</strong></p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fw46ro5d4aj20d909r40m.jpg" alt="ClosestPair3"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Main message:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从最简单的case入手&lt;/li&gt;
&lt;li&gt;看能否分，能否combine&lt;/li&gt;
&lt;li&gt;不求最优，只要次优&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="algorithm" scheme="http://yoursite.com/categories/algorithm/"/>
    
    
      <category term="Algorithm Design and Analysis" scheme="http://yoursite.com/tags/Algorithm-Design-and-Analysis/"/>
    
      <category term="Basic algorithm design technique" scheme="http://yoursite.com/tags/Basic-algorithm-design-technique/"/>
    
      <category term="Divide-and-Conquer" scheme="http://yoursite.com/tags/Divide-and-Conquer/"/>
    
      <category term="Sort Algorithm" scheme="http://yoursite.com/tags/Sort-Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Algorithm Design and Analysis - Overview</title>
    <link href="http://yoursite.com/2018/09/14/Algorithm-Design-and-Analysis-Overview/"/>
    <id>http://yoursite.com/2018/09/14/Algorithm-Design-and-Analysis-Overview/</id>
    <published>2018-09-14T12:51:42.000Z</published>
    <updated>2018-10-20T10:50:58.049Z</updated>
    
    <content type="html"><![CDATA[<p>今天上了卜东波老师的第一次算法课，对算法的概况有了一个大体的了解，在这里对今天的内容做一些总结。【Three solutions：Induction, Improvemrnt and Enumeration】</p><a id="more"></a><h2 id="一、Mind-Map"><a href="#一、Mind-Map" class="headerlink" title="一、Mind Map"></a>一、Mind Map</h2><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fv9hdwxga9j20j60j0gmj.jpg" alt="MindMap"></p><h2 id="二、三种基本的算法策略"><a href="#二、三种基本的算法策略" class="headerlink" title="二、三种基本的算法策略"></a>二、三种基本的算法策略</h2><p>基本上，所有的算法题都可以用三种策略解决。</p><ul><li><strong>Divide-and-conquer</strong>: Let’s start from the “smallest”<br>problem first, and investigate whether a large problem can<br><strong><em>reduce to smaller subproblems</em></strong>.</li></ul><p>分治法，将问题分解为小的问题，从最小问题出发解决问题。</p><p>See: <a  href ="http://imjiawen.com/2018/09/24/Algorithm-Design-and-Analysis-Divide-and-Conquer/">Algorithm_Design_and Analysis-Divide-and-Conquer</a></p><ul><li><strong>“Intelligent” Enumeration</strong>: Consider an optimization<br>problem. If the solution can be constructed step by step, we might enumerate <strong><em>all possible complete solutions</em></strong> by constructing a <strong><em>partial solution tree</em></strong>. Due to the huge size of the search tree, some techniques should be employed to prune it.</li></ul><p>动态规划就是一种枚举所有可能性的算法，see：<a  href ="http://imjiawen.com/2018/09/24/Algorithm-Design-and-Analysis-Divide-and-Conquer/">Algorithm Design and Analysis - Dynamic programming</a></p><p>枚举法，枚举所有的解。可使用trick(如设定下界)来加快。</p><ul><li><strong>Improvement</strong>: Let’s start from <strong><em>an initial complete<br>solution</em></strong>, and try to improve it step by step.</li></ul><p>若无法将问题分解，就从质量不太好的完整解出发，逐步优化</p><h2 id="三、例题"><a href="#三、例题" class="headerlink" title="三、例题"></a>三、例题</h2><p><strong>EX1.Calculating the greatest common divisor (gcd)</strong><br>求最小公约数</p><p>The greatest common divisor of two integers a and b, when at least one of them is not zero, is the largest positive integer that divides the numbers without a remainder.</p><pre><code>INPUT: two n-bits numbers a, and b (a &gt;= b)OUTPUT: gcd(a; b)</code></pre><p>已知gcd(1; 0) = 1;如何求解gcd(1949; 101)?</p><p>可将复杂问题分解成小的问题(辗转相除法)：gcd(1949; 101) = gcd(101; 1949 mod 101) = gcd(101; 30)= gcd(30; 101 mod 30) = gcd(30; 11)= gcd(11; 30 mod 11) = gcd(11; 8)= gcd(8; 3) = gcd(3; 2) =<br>gcd(2; 1) = gcd(1; 0) = 1</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">function Euclid(a; b)</span><br><span class="line">if b &#x3D; 0 then</span><br><span class="line">return a;</span><br><span class="line">end if</span><br><span class="line">return Euclid(b; a mod b);</span><br></pre></td></tr></table></figure><p><strong>EX2.traveling salesman problem (TSP)</strong><br>周游城市的最短距离</p><pre><code>INPUT: n cities V = {1; 2;...; n}, and a distance matrix D, where dij (1 &lt;= i; j &lt;= n) denotes the distance between city i and j.OUTPUT: the shortest tour that visits each city exactly once and returns to the origin city.</code></pre><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fv9he4eu4dj204b04mmx9.jpg" alt="map1"></p><p><strong><em>Trial 1: Divide and conquer</em></strong></p><p>我们可通过计算 M(S,e) 来计算最小距离。S为要拜访的节点的集合，e为结束节点。</p><p>如，最短的距离我们可通过以下式子来计算：</p><p>min{ d2;1 +M({3; 4}; 2); d3;1 +M({2; 4}; 3); d4;1 +M({2; 3}; 4)}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;算是一种动态规划算法</span><br><span class="line">function TSP(V;D)</span><br><span class="line">return min&#123; M(V - &#123;e&#125;; e) + de1&#125;;  &#x2F;&#x2F;e属于V且e不为1</span><br><span class="line"></span><br><span class="line">function M(S; e)</span><br><span class="line">if S &#x3D; &#123;v&#125; then</span><br><span class="line">M(S; e) &#x3D; d1v + dve;</span><br><span class="line">return M(S; e);</span><br><span class="line">end if</span><br><span class="line">return min&#123; M(S - &#123;i&#125;; i) + dei&#125;;  &#x2F;&#x2F;i属于S，i不为e</span><br></pre></td></tr></table></figure><p><strong><em>Trial 2: Improvement strategy</em></strong></p><p>从一个完整的解中开始，一步一步去完善它。Newton法，随机梯度下降和MC都用到了这个策略。但这种方法不一定能够获得最优解。可得到最优解的情况：线性规划，二次规划，网络流等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">function GenericImprovement(G;D)  &#x2F;&#x2F;通用，逐步迭代完整解</span><br><span class="line">Let s be an initial tour;   &#x2F;&#x2F;初始解的选择很重要</span><br><span class="line">while TRUE do</span><br><span class="line">Select a new tour s′ from the neighbourhood of s; &#x2F;&#x2F;扰动越小越好</span><br><span class="line">if s′ is shorter than s then</span><br><span class="line">s &#x3D; s′;</span><br><span class="line">end if</span><br><span class="line">if stopping(s) then  &#x2F;&#x2F;s满足退出条件</span><br><span class="line">return s;</span><br><span class="line">end if</span><br><span class="line">end while</span><br></pre></td></tr></table></figure><p><strong><em>Trial 3: Intelligent” enumeration strategy</em></strong></p><p>完整的解可以表示为n条边的排列。将边缘按照一定顺序排列，一个完整的解可以被表示为：X = [x1, x2,…, xm]。 例如：a -&gt; b -&gt; c -&gt; d -&gt; e -&gt; a 可以被表示为 X = [1, 0, 0, 1, 1, 0, 0, 1, 0, 1]。<br>所有的环游都可以写成这种形式，我们就能枚举出所有的解。</p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fv9he4hzsgj208a06ewf0.jpg" alt="map2"></p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fv9heynqcqj20i2072gn3.jpg" alt="tree"></p><p>子节点：表示一个完整的解</p><p>内部解：表示一个部分解，是一个已知item的子集</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">function GenericBacktrack(P0)  &#x2F;&#x2F;枚举所有的解</span><br><span class="line">Let A &#x3D; fP0g. &#x2F;&#x2F;Start with the original problem P0. Here, A</span><br><span class="line">denotes the active subproblems that are unexplored.</span><br><span class="line">best_so_far &#x3D; 1;   &#x2F;&#x2F;当前知道的最短路程</span><br><span class="line">while A ̸&#x3D; NULL do  &#x2F;&#x2F;当还有节点要扩展时</span><br><span class="line">Choose and remove a subproblem P from A;</span><br><span class="line">Expand P into smaller subproblems P1, P2,..., Pk;</span><br><span class="line">for i &#x3D; 1 to k do</span><br><span class="line">if Pi corresponds to a complete solution then</span><br><span class="line">Update best_so_far if the corresponding objective function value is better;  &#x2F;&#x2F;对应一个完整解</span><br><span class="line">else</span><br><span class="line">Insert Pi into A;   &#x2F;&#x2F;对应一个部分解</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">end while</span><br><span class="line">return best_so_far;</span><br></pre></td></tr></table></figure><p>然而，这种方式计算量巨大，需要花费指数倍的时间，且我们无需在内存中存储整个树。因此，我们可以从中剔除一些低质量的或者不符合条件的部分解（贪心算法）。我们可以使用heuristic functions 和下界(lower bound functions)来评估部分解的质量。【这是EM算法的核心】</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">function IntelligentBacktrack(P0)</span><br><span class="line">Let A &#x3D; fP0g. &#x2F;&#x2F; Start with the original problem P0. Here A denotes the active subproblems that are unexplored.</span><br><span class="line">best_so_far &#x3D; infinite;</span><br><span class="line">while A ̸&#x3D; NULL do</span><br><span class="line">Choose a subproblem P in A with lower bound less than best_so_far;</span><br><span class="line">Remove P from A;</span><br><span class="line">Expand P into smaller subproblems P1, P2, ..., Pk,</span><br><span class="line">for i &#x3D; 1 to k do</span><br><span class="line">if Pi corresponds to a complete solution then</span><br><span class="line">Update best so far;</span><br><span class="line">else</span><br><span class="line">if lowerbound(Pi) &lt;&#x3D; best so far then Insert Pi into A;</span><br><span class="line">end if</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">end while</span><br><span class="line">return best_so_far;</span><br></pre></td></tr></table></figure><h2 id="四、小结"><a href="#四、小结" class="headerlink" title="四、小结"></a>四、小结</h2><ol><li>先观察问题的结构，解的形式，再设计算法</li><li>能分解成子问题是一个非常有效的信号</li><li>在优化问题中，下界信息非常重要</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天上了卜东波老师的第一次算法课，对算法的概况有了一个大体的了解，在这里对今天的内容做一些总结。【Three solutions：Induction, Improvemrnt and Enumeration】&lt;/p&gt;
    
    </summary>
    
    
      <category term="algorithm" scheme="http://yoursite.com/categories/algorithm/"/>
    
    
      <category term="Algorithm Design and Analysis" scheme="http://yoursite.com/tags/Algorithm-Design-and-Analysis/"/>
    
      <category term="Course summary" scheme="http://yoursite.com/tags/Course-summary/"/>
    
      <category term="Overview" scheme="http://yoursite.com/tags/Overview/"/>
    
  </entry>
  
  <entry>
    <title>Dynamic programming 动态规划算法</title>
    <link href="http://yoursite.com/2018/08/14/Dynamic-programming-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2018/08/14/Dynamic-programming-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AE%97%E6%B3%95/</id>
    <published>2018-08-14T15:08:47.000Z</published>
    <updated>2018-09-08T14:20:35.761Z</updated>
    
    <content type="html"><![CDATA[<p>动态规划算法在编程题中运用场景很广(我觉得也有点难:( )，这篇博文主要总结了动态规划算法的基本思想以及一些例题。</p><a id="more"></a><h2 id="一、基本概念"><a href="#一、基本概念" class="headerlink" title="一、基本概念"></a>一、基本概念</h2><p>动态规划过程是：每次决策依赖于当前状态，又随即引起状态的转移。一个决策序列就是在变化的状态中产生出来的，所以，这种<strong>多阶段最优化决策解决问题的过程</strong>就称为动态规划。</p><h2 id="二、基本思想与策略"><a href="#二、基本思想与策略" class="headerlink" title="二、基本思想与策略"></a>二、基本思想与策略</h2><p>动态规划算法与分治法的区别：<strong>适合于用动态规划法求解的问题，经分解后得到的子问题往往不是互相独立的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）</strong>。</p><p>动态规划算法将待求解的问题分解为若干个子阶段，按顺序求解子阶段，前一子问题的解决为后一子问题的求解提供了有用信息。在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解。依次解决各子问题，最后一个子问题就是初始问题的解。</p><p>由于动态规划解决的问题多数有重叠子问题这个特点，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。</p><h2 id="三、适用情况"><a href="#三、适用情况" class="headerlink" title="三、适用情况"></a>三、适用情况</h2><p>一般动态规划问题具有三个性质：</p><ol><li>最优化原理：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理。</li><li>无后效性：即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关。</li><li>有重叠子问题：即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。（该性质<strong>并不是动态规划适用的必要条件</strong>，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势）有些子问题会被重复计算多次。动态规划算法正是利用了这种子问题的重叠性质，对每一个子问题只计算一次，然后将其计算结果保存在一个<strong>表格</strong>中，当再次需要计算已经计算过的子问题时，只是在表格中简单地查看一下结果，从而获得较高的效率。</li></ol><p>note:先创建一个哈希表，将每次不同参数的计算结果存入哈希表，当遇到相同参数时，再从哈希表里取出，就避免了重复计算<strong>【备忘录算法】</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;上台阶问题中运用备忘录算法</span><br><span class="line">int getClimbingWays(int n, HashMap&lt;Integer, Integer&gt; map)&#123;</span><br><span class="line">    if(n&lt;1)&#123;</span><br><span class="line">        return 0;</span><br><span class="line">    &#125;</span><br><span class="line">    if(n&#x3D;&#x3D;1)&#123;</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line">     if(n&#x3D;&#x3D;2)&#123;</span><br><span class="line">        return 2;</span><br><span class="line">    &#125;</span><br><span class="line">     if(map.contains(n))&#123;</span><br><span class="line">        return map.get(n);</span><br><span class="line">    &#125;else&#123;</span><br><span class="line">        int value &#x3D; getClimbingWays(n-1) + getClimbingWays(n-2);</span><br><span class="line">        map.put(n,value);</span><br><span class="line">        return value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="四、求解的基本步骤"><a href="#四、求解的基本步骤" class="headerlink" title="四、求解的基本步骤"></a>四、求解的基本步骤</h2><p>动态规划所处理的问题是一个<strong>多阶段决策问题</strong>，一般由初始状态开始，通过对中间阶段决策的选择，达到结束状态。这些决策形成了一个决策序列，同时确定了完成整个过程的一条活动路线(通常是求最优的活动路线)。如下所示。动态规划的设计都有着一定的模式，一般要经历以下几个步骤。</p><p><strong>初始状态 -&gt; |决策1| -&gt; |决策2| -&gt; … |决策n| -&gt; 结束状态</strong></p><ol><li><strong>划分阶段</strong>：按照问题的时间或空间特征，把问题分为若干个阶段。在划分阶段时，注意<strong>划分后的阶段一定要是有序的或者是可排序的</strong>，否则问题就无法求解。</li><li><strong>确定状态和状态变量</strong>：将问题发展到各个阶段时所处于的各种客观情况用不同的状态表示出来。当然，状态的选择要满足<strong>无后效性</strong>。</li><li><strong>确定决策并写出状态转移方程</strong>：因为决策和状态转移有着天然的联系，<strong>状态转移就是根据上一阶段的状态和决策来导出本阶段的状态</strong> 。所以如果确定了决策，状态转移方程也就可写出。但事实上常常是反过来做，<strong>根据相邻两个阶段的状态之间的关系来确定决策方法和状态转移方程</strong>。</li><li><strong>寻找边界条件</strong>：给出的状态转移方程是一个递推式，需要一个递推的终止条件或边界条件。</li></ol><p>一般，只要解决问题的<strong>阶段</strong>、<strong>状态</strong>和<strong>状态转移决策</strong>确定了，就可以写出状态转移方程（包括边界条件）。<br>实际应用中可以按以下几个简化的步骤进行设计：</p><ol><li>描述最优解的结构</li><li>递归定义最优解的值</li><li>按自底向上的方式计算最优解的值  //此三步构成动态规划解的基础</li><li>由计算出的结果构造一个最优解  //若只要求计算最优解的值可省略</li></ol><h2 id="五、算法实现的说明"><a href="#五、算法实现的说明" class="headerlink" title="五、算法实现的说明"></a>五、算法实现的说明</h2><p>动态规划的主要难点在于理论上的设计，也就是上面4个步骤的确定，一旦设计完成，实现部分就会非常简单。</p><pre><code> 使用动态规划求解问题，最重要的就是确定动态规划三要素：（1）问题的阶段 （2）每个阶段的状态（3）从前一个阶段转化到后一个阶段之间的递推关系。</code></pre><p>递推关系必须是从次小的问题开始到较大的问题之间的转化，从这个角度来说，动态规划往往可以用递归程序来实现，不过因为<strong>递推可以充分利用前面保存的子问题的解来减少重复计算，所以对于大规模问题来说，递归有不可比拟的优势</strong>，这也是动态规划算法的核心之处。</p><p>确定了动态规划的这三要素，<strong>整个求解过程就可以用一个最优决策表来描述，最优决策表是一个二维表，其中行表示决策的阶段，列表示问题状态</strong>，表格需要<strong>填写的数据一般对应此问题的在某个阶段某个状态下的最优值</strong>（如最短路径，最长公共子序列，最大价值等），填表的过程就是根据递推关系，从1行1列开始，以行或者列优先的顺序，依次填写表格，最后根据整个表格的数据通过简单的取舍或者运算求得问题的最优解。</p><p><em>f(n,m)=max{f(n-1,m), f(n-1,m-w[n])+P(n,m)}</em></p><h2 id="六、经典动态算法题"><a href="#六、经典动态算法题" class="headerlink" title="六、经典动态算法题"></a>六、经典动态算法题</h2><p><strong>例题一：上台阶问题</strong></p><p>有n级台阶，一个人每次上一级或者两级，问有多少种走完n级台阶的方法。</p><p>分析：动态规划的实现的关键在于能不能准确合理的用动态规划表来抽象出 实际问题。在这个问题上，我们让f(n)表示走上n级台阶的方法数。</p><p>那么当n为1时，f(n) = 1,n为2时，f(n) =2,就是说当台阶只有一级的时候，方法数是一种，台阶有两级的时候，方法数为2。那么当我们要走上n级台阶，必然是从n-1级台阶迈一步或者是从n-2级台阶迈两步，所以到达n级台阶的方法数必然是到达n-1级台阶的方法数加上到达n-2级台阶的方法数之和。即f(n) = f(n-1)+f(n-2)，我们用dp[n]来表示动态规划表，dp[i],i&gt;0,i&lt;=n,表示到达i级台阶的方法数。</p><p><strong><em>迭代法（自顶向下）</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*dp是全局数组，大小为n,全部初始化为0，是题目中的动态规划表*&#x2F;</span><br><span class="line">int fun(int n)&#123;</span><br><span class="line">if (n&#x3D;&#x3D;1||n&#x3D;&#x3D;2)</span><br><span class="line">return n;</span><br><span class="line">&#x2F;*判断n-1的状态有没有被计算过*&#x2F;</span><br><span class="line">if (!dp[n-1])</span><br><span class="line">dp[n-1] &#x3D; fun(n-1);</span><br><span class="line">if(!dp[n-2])</span><br><span class="line">dp[n-2]&#x3D;fun(n-2);</span><br><span class="line">return dp[n-1]+dp[n-2];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>LeetCode相关问题：<br><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fv2hkwxy7kj20ez0c4q32.jpg" alt="leetcode问题"><br><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fv2hkwpb75j20dv06kdfs.jpg" alt="解法"></p><p><strong><em>动态规划求解（自底向上）</em></strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">int getClimbingWays(int n, HashMap&lt;Integer, Integer&gt; map)&#123;</span><br><span class="line">    if(n&lt;1)&#123;</span><br><span class="line">        return 0;</span><br><span class="line">    &#125;</span><br><span class="line">    if(n&#x3D;&#x3D;1)&#123;</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line">    if(n&#x3D;&#x3D;2)&#123;</span><br><span class="line">        return 2;</span><br><span class="line">    &#125;</span><br><span class="line">    int a &#x3D; 1;</span><br><span class="line">    int b &#x3D; 2;</span><br><span class="line">    int tmp &#x3D; 0;</span><br><span class="line">    </span><br><span class="line">    for (int i &#x3D; 3; i&lt;&#x3D;n; i++)&#123;</span><br><span class="line">        tmp &#x3D; a + b;</span><br><span class="line">        a &#x3D; b;</span><br><span class="line">        b &#x3D; tmp;</span><br><span class="line">    &#125;</span><br><span class="line">    return tmp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>例题二：国王与金矿（与01背包问题类似）</strong></p><p>有一个国家发现了5座金矿，每座金矿的黄金储量不同，需要参与挖掘的工人数也不同。参与挖矿工人的总数是10人。每座金矿要么全挖，要么不挖，不能派出一半人挖取一半金矿。要求用程序求解出，要想得到尽可能多的黄金，应该选择挖取哪几座金矿？</p><p>500金/5人；200金/3人；300金/4人；350金/3人；400金/5人</p><p>问题的状态转移方程式：</p><p>F(n,w) = 0 (n&lt;=1, w&lt;p[0]);  //若给定的工人数量不够挖取第一座金矿</p><p>F(n,w) = g[0] (n==1, w&gt;=p[0]);</p><p>F(n,w) = F(n-1,w) (n&gt;1, w&lt;p[n-1])</p><p>F(n,w) = max(F(n-1,w), F(n-1,w-p[n-1])+g[n-1]) (n&gt;1, w&gt;=p[n-1]) //最后一个矿有选择不挖和挖两个选择，在其中选最优的选择</p><p><strong><em>排列组合</em></strong></p><p>每一座金矿都有挖与不挖两种选择，如果有N座金矿，排列组合起来就有2^N种选择。对所有可能性做遍历，排除那些使用工人数超过10的选择，在剩下的选择里找出获得金币数最多的选择。（O(2^N)）</p><p><strong><em>简单递归</em></strong></p><p>把状态转移方程式翻译成递归程序，递归的结束的条件就是方程式当中的边界。因为每个状态有两个最优子结构，所以递归的执行流程类似于一颗高度为N的二叉树。方法的时间复杂度是O(2^N)。</p><p><strong><em>备忘录算法</em></strong></p><p>在简单递归的基础上增加一个HashMap备忘录，用来存储中间结果。HashMap的Key是一个包含金矿数N和工人数W的对象，Value是最优选择获得的黄金数。方法的时间复杂度和空间复杂度相同，都等同于备忘录中不同Key的数量。</p><p><strong><em>动态规划</em></strong></p><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fv28bf1ocoj20hz04djti.jpg" alt="计算过程，除了第一行以外，每个格子都是由前一行的一个或者两个格子推导而来"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">int getMostGold(int n, int w, int[] g, int[] p)&#123;</span><br><span class="line">    int[] preResults &#x3D; new int[p.length];</span><br><span class="line">    int[] results &#x3D; new int[p.length];</span><br><span class="line">    &#x2F;&#x2F;填充边界格子的值</span><br><span class="line">    for(int i&#x3D;0; i&lt;&#x3D;n; i++)&#123;</span><br><span class="line">        if(i &lt; p[0])&#123;</span><br><span class="line">            preResults[i] &#x3D; 0;</span><br><span class="line">        &#125;else&#123;</span><br><span class="line">            preResults[i] &#x3D; g[0];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;填充其余格子的值，外层循环是金矿数量，内层循环是工人数</span><br><span class="line">    for(int i&#x3D;0; i&lt;&#x3D;n; i++)&#123;</span><br><span class="line">        for(int j&#x3D;0;j&lt;&#x3D;w;j++)&#123;</span><br><span class="line">            if(j &lt; p[i])&#123;</span><br><span class="line">                results[j]&#x3D;preResults[j]; &#x2F;&#x2F;这里代码有问题，java中数组不能直接赋值，可改用clone方式赋值</span><br><span class="line">            &#125;else&#123;</span><br><span class="line">                results[j]&#x3D;Math.max(preResults[j],preResults[j-p[i]]+g[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        preResults &#x3D; results;</span><br><span class="line">    &#125;</span><br><span class="line">    return preResults[n];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>方法的时间复杂度是 O(n * w)，空间复杂度是(w)。需要注意的是，当金矿只有5座的时候，动态规划的性能优势还没有体现出来。当金矿有10座，甚至更多的时候，动态规划就明显具备了优势。由于动态规划方法的时间和空间都和W成正比，而简单递归却和W无关，所以当工人数量很多的时候，动态规划反而不如递归。</p><p><strong>例题三：最长公共子序列</strong></p><p>如果字符串一的所有字符按其在字符串中的顺序出现在另外一个字符串二中，<br>则字符串一称之为字符串二的子串。</p><p>注意，并不要求子串（字符串一）的字符必须连续出现在字符串二中。<br>请编写一个函数，输入两个字符串，求它们的最长公共子串，并打印出最长公共子串。<br>例如：输入两个字符串BDCABA和ABCBDAB，字符串BCBA和BDAB都是是它们的最长公共子串，<br>则输出它们的长度4，并打印任意一个子串。</p><p>LCS问题具有重叠子问题的性质，因此有些子问题可通过“查表”而直接得到。</p><p>用二维数组c[i][j]记录串x1x2⋯xi与y1y2⋯yj的LCS长度，则可得到状态转移方程<br><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fv2hb144upj20gf03kwfd.jpg" alt="状态转移方程"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">public class LCSequence &#123;</span><br><span class="line">    &#x2F;&#x2F;求解str1 和 str2 的最长公共子序列</span><br><span class="line">    public static int LCS(String str1, String str2)&#123;</span><br><span class="line">        int[][] c &#x3D; new int[str1.length() + 1][str2.length() + 1];</span><br><span class="line">&#x2F;&#x2F;初始化</span><br><span class="line">        for(int row &#x3D; 0; row &lt;&#x3D; str1.length(); row++)</span><br><span class="line">            c[row][0] &#x3D; 0;</span><br><span class="line">        for(int column &#x3D; 0; column &lt;&#x3D; str2.length(); column++)</span><br><span class="line">            c[0][column] &#x3D; 0;</span><br><span class="line">        </span><br><span class="line">        for(int i &#x3D; 1; i &lt;&#x3D; str1.length(); i++)</span><br><span class="line">            for(int j &#x3D; 1; j &lt;&#x3D; str2.length(); j++)</span><br><span class="line">            &#123;</span><br><span class="line">                if(str1.charAt(i-1) &#x3D;&#x3D; str2.charAt(j-1))</span><br><span class="line">                    c[i][j] &#x3D; c[i-1][j-1] + 1;</span><br><span class="line">                else if(c[i][j-1] &gt; c[i-1][j])</span><br><span class="line">                    c[i][j] &#x3D; c[i][j-1];</span><br><span class="line">                else</span><br><span class="line">                    c[i][j] &#x3D; c[i-1][j];</span><br><span class="line">            &#125;</span><br><span class="line">        return c[str1.length()][str2.length()];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Reference："><a href="#Reference：" class="headerlink" title="Reference："></a>Reference：</h2><ol><li><a href="http://www.cnblogs.com/steven_oyj/archive/2010/05/22/1741374.html" target="_blank" rel="noopener">http://www.cnblogs.com/steven_oyj/archive/2010/05/22/1741374.html</a></li><li><a href="http://www.cnblogs.com/pengyingh/articles/2396427.html" target="_blank" rel="noopener">http://www.cnblogs.com/pengyingh/articles/2396427.html</a></li><li><a href="https://www.sohu.com/a/153858619_466939" target="_blank" rel="noopener">https://www.sohu.com/a/153858619_466939</a></li><li><a href="https://www.cnblogs.com/hapjin/p/5572483.html" target="_blank" rel="noopener">https://www.cnblogs.com/hapjin/p/5572483.html</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;动态规划算法在编程题中运用场景很广(我觉得也有点难:( )，这篇博文主要总结了动态规划算法的基本思想以及一些例题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="algorithm" scheme="http://yoursite.com/categories/algorithm/"/>
    
    
      <category term="Dynamic programming" scheme="http://yoursite.com/tags/Dynamic-programming/"/>
    
      <category term="Algorithm summary" scheme="http://yoursite.com/tags/Algorithm-summary/"/>
    
  </entry>
  
  <entry>
    <title>Hello world</title>
    <link href="http://yoursite.com/2018/05/01/Hello-world/"/>
    <id>http://yoursite.com/2018/05/01/Hello-world/</id>
    <published>2018-05-01T02:11:12.000Z</published>
    <updated>2020-06-05T02:11:56.192Z</updated>
    
    <content type="html"><![CDATA[<p>Hello guys, this is Jiawen.<br>Nice to meeting you :)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Hello guys, this is Jiawen.&lt;br&gt;Nice to meeting you :)&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="life" scheme="http://yoursite.com/categories/life/"/>
    
    
      <category term="life" scheme="http://yoursite.com/tags/life/"/>
    
      <category term="TheFirstPost" scheme="http://yoursite.com/tags/TheFirstPost/"/>
    
  </entry>
  
</feed>
